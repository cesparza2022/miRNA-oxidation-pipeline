# -*- coding: utf-8 -*-
"""exploratory_mi-8oG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XAh7vae9I8lA0gogZCj1YlBchXeA11v0
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import gzip
from scipy.cluster.hierarchy import linkage, dendrogram
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

with gzip.open("/content/miRNA_count.Q33.txt.gz") as file:
    df = pd.read_csv(file, sep="\t")

# Quick check
print(df.shape)
df.head()

def split_multiple_mutations(df, col="pos:mut"):
    """
    Splits rows in a DataFrame that have multiple mutations listed in a single cell
    into separate rows, keeping all other columns unchanged.

    The function assumes that mutations in the column are separated by commas.
    For example, if a row has "11:GT,22:TA" in the specified column, the resulting
    DataFrame will have two rows for that entry: one with "11:GT" and another with "22:TA".

    Parameters:
        df (pandas.DataFrame): Input DataFrame.
        col (str): Name of the column that contains mutation information.
                   Expected formats include "PM" or "11:GT" or "11:GT,22:TA", etc.

    Returns:
        pandas.DataFrame: A new DataFrame with each mutation in its own row.

    Example:
        Input DataFrame:
            miRNA name    pos:mut
            miR-1         PM
            miR-2         11:GT,22:TA
            miR-3         15:AC

        Output DataFrame:
            miRNA name    pos:mut
            miR-1         PM
            miR-2         11:GT
            miR-2         22:TA
            miR-3         15:AC
    """
    df_copy = df.copy()
    df_copy["mut_list"] = df_copy[col].str.split(",")
    df_exploded = df_copy.explode("mut_list", ignore_index=True)
    df_exploded["mut_list"] = df_exploded["mut_list"].str.strip()
    df_exploded[col] = df_exploded["mut_list"]
    df_exploded.drop(columns=["mut_list"], inplace=True)
    return df_exploded

def extract_numeric_position(df, col="pos:mut", new_col="pos_numeric"):
    """
    Extracts the numeric portion from a mutation column and adds it as a new column.

    This function assumes that the mutation information is stored in the specified column
    in the format "number:mutation" (for example, "11:GT"). It extracts the number (e.g., 11)
    and creates a new column with that numeric value. If the cell does not contain a colon
    (":") or the value is not in the expected format (e.g., "PM"), it returns None.

    Parameters:
        df (pandas.DataFrame): The input DataFrame.
        col (str): Name of the column containing the mutation information (default "pos:mut").
        new_col (str): Name for the new column that will contain the extracted numeric positions
                       (default "pos_numeric").

    Returns:
        pandas.DataFrame: A new DataFrame with an additional column (new_col) containing the numeric positions.

    Example:
        Input DataFrame:
            miRNA name       pos:mut
            miR-1            PM
            miR-2            11:GT,22:TA
            miR-3            15:AC

        Output DataFrame (if applied after exploding, for example):
            miRNA name       pos:mut   pos_numeric
            miR-1            PM        None
            miR-2            11:GT     11
            miR-2            22:TA     22
            miR-3            15:AC     15
    """
    df_copy = df.copy()
    df_copy[new_col] = df_copy[col].apply(lambda x: int(x.split(":")[0]) if isinstance(x, str) and ":" in x else None)
    return df_copy


def filter_by_transversion(df, transversion, col="pos:mut"):
    """
    Filters the DataFrame to include only rows where the specified mutation code is present.

    The function checks if the given transversion string (e.g., "GT", "AC", "TA", etc.)
    is a substring of the value in the specified column. If a row's cell in that column
    contains the mutation code, it is retained.

    Parameters:
        df (pandas.DataFrame): Input DataFrame.
        transversion (str): The mutation code to filter for (e.g., "GT").
        col (str): The name of the column that contains mutation information.

    Returns:
        pandas.DataFrame: A filtered DataFrame containing only rows where the mutation code is present.

    Example:
        If a row has "11:GT,22:TA" in the "pos:mut" column and transversion is "GT",
        that row will be included in the result.
    """
    filtered_df = df[df[col].apply(lambda x: transversion in x if isinstance(x, str) else False)].copy()
    return filtered_df


def filter_by_region(df, min_pos=1, max_pos=None, col="pos:mut"):
    """
    Filters the DataFrame based on the numeric position extracted from the mutation column.

    This function extracts the numeric position from the specified column (expected format: "position:mutation", e.g., "11:GT").
    It then retains only the rows where the position is greater than or equal to min_pos and, if provided,
    less than or equal to max_pos. Rows where the position cannot be determined (e.g., "PM") are excluded.

    Parameters:
        df (pandas.DataFrame): Input DataFrame.
        min_pos (int, optional): The minimum position (inclusive). Defaults to 1.
        max_pos (int, optional): The maximum position (inclusive). If None, no upper bound is applied.
        col (str): The name of the column containing mutation information.

    Returns:
        pandas.DataFrame: A new DataFrame containing only rows with positions within the specified range.

    Example:
        If a row has "11:GT" and you call filter_by_region(df, min_pos=1, max_pos=8, col="pos:mut"),
        that row will be excluded because 11 > 8.
    """
    df_copy = df.copy()
    # Extract numeric position if available; return None otherwise.
    df_copy['position'] = df_copy[col].apply(lambda x: int(x.split(":")[0]) if isinstance(x, str) and ":" in x else None)

    if max_pos is not None:
        filtered_df = df_copy[(df_copy['position'].notna()) & (df_copy['position'] >= min_pos) & (df_copy['position'] <= max_pos)]
    else:
        filtered_df = df_copy[(df_copy['position'].notna()) & (df_copy['position'] >= min_pos)]

    filtered_df = filtered_df.drop(columns=["position"])
    return filtered_df


def convert_all_reads_to_percent(df, total_suffix=" (PM+1MM+2MM)"):
    """
    Converts all read count columns in the DataFrame to percentages using the corresponding total read counts.

    Assumptions:
      - The DataFrame has at least two identifier columns: "miRNA name" and "pos:mut".
      - The read count columns are those that do not contain the total_suffix and are not identifier columns.
      - For each read count column, the corresponding total is expected to be in a column named:
            read_column + total_suffix

    For each pair, the percentage is calculated as:
            percentage = (read count / total count) * 100
    The read count columns are replaced (in-place) by the computed percentage values,
    and are renamed by appending " (mm%)". The original column order is preserved.

    Parameters:
        df (pandas.DataFrame): The input DataFrame.
        total_suffix (str): Suffix that identifies the total columns. Default is " (PM+1MM+2MM)".

    Returns:
        pandas.DataFrame: A new DataFrame with read count columns converted to percentages,
                          with the same column order as the original.

    Example:
        If the DataFrame has the following columns:
            "miRNA name", "pos:mut", "Sample1", "Sample2",
            "Sample1 (PM+1MM+2MM)", "Sample2 (PM+1MM+2MM)"
        Then, the function computes:
            "Sample1 (mm%)" = (Sample1 / Sample1 (PM+1MM+2MM)) * 100
            "Sample2 (mm%)" = (Sample2 / Sample2 (PM+1MM+2MM)) * 100
        And the resulting DataFrame will preserve the original column order.
    """
    df_copy = df.copy()
    # Save the original column order.
    original_cols = df_copy.columns.tolist()

    # Identifier columns that should be preserved.
    id_cols = ["miRNA name", "pos:mut"]
    # Identify read count columns (those not in id_cols and not containing total_suffix)
    read_cols = [col for col in original_cols if col not in id_cols and total_suffix not in col]

    for r in read_cols:
        total_col = r + total_suffix
        if total_col in df_copy.columns:
            # Compute the percentage values.
            percentage = (df_copy[r] / df_copy[total_col]) * 100
            # Replace the values in the read column with these percentages.
            df_copy[r] = percentage
            # Rename the read column to indicate that it now contains percentages.
            df_copy.rename(columns={r: r + " (mm%)"}, inplace=True)
        else:
            print(f"Warning: Total column not found for '{r}' (expected '{total_col}').")

    # Reconstruct the column order, replacing any read column names with their new names.
    new_order = []
    for col in original_cols:
        if col in read_cols:
            new_order.append(col + " (mm%)")
        else:
            new_order.append(col)

    # Only keep columns that exist in the modified DataFrame.
    new_order = [col for col in new_order if col in df_copy.columns]

    return df_copy[new_order]


def filter_columns_by_pattern(df, pattern, id_cols=["miRNA name", "pos:mut"]):
    """
    Filters the DataFrame to keep only the identifier columns (e.g., "miRNA name" and "pos:mut")
    along with all columns whose names contain the specified pattern.

    This is useful when you want to restrict your analysis to a subset of samples that
    share a common identifier (e.g., "SOD1") in their column names.

    Parameters:
        df (pandas.DataFrame): The input DataFrame.
        pattern (str): The pattern to search for in the column names (e.g., "SOD1").
        id_cols (list of str): List of identifier columns that should always be kept.
                               Defaults to ["miRNA name", "pos:mut"].

    Returns:
        pandas.DataFrame: A new DataFrame containing only the identifier columns and
                          those columns that include the specified pattern.

    Example:
        Given a DataFrame with columns:
            "miRNA name", "pos:mut", "SOD1_sample1", "SOD1_sample1 (PM+1MM+2MM)", "TDP43_sample2", ...
        Calling:
            filter_columns_by_pattern(df, "SOD1")
        will return a DataFrame with:
            "miRNA name", "pos:mut", "SOD1_sample1", "SOD1_sample1 (PM+1MM+2MM)"
    """
    filtered_cols = [col for col in df.columns if col in id_cols or pattern in col]
    return df[filtered_cols]



def get_read_and_total_columns(df,
                               id_cols=["miRNA name", "pos:mut"],
                               total_suffix=" (PM+1MM+2MM)",
                               pos_col="pos_numeric"):
    """
    Returns two lists of column names:
      - read_cols: Those columns that contain the read counts or normalized frequencies.
        They are assumed to be all columns (except the identifier columns and any column
        that is a total column, i.e. contains total_suffix).
      - total_cols: Those columns that contain the totals (their names include total_suffix).

    The function ignores any column specified in id_cols and also excludes the position column.

    Parameters:
        df (pandas.DataFrame): The processed DataFrame.
        id_cols (list of str): List of identifier columns to exclude (default: ["miRNA name", "pos:mut"]).
        total_suffix (str): Suffix that identifies total columns (default: " (PM+1MM+2MM)").
        pos_col (str): Name of the numeric position column to exclude (default: "pos_numeric").

    Returns:
        tuple: (read_cols, total_cols) where each is a list of column names.

    Example:
        For a DataFrame with columns:
            ["miRNA name", "pos:mut", "Sample1", "Sample2",
             "Sample1 (PM+1MM+2MM)", "Sample2 (PM+1MM+2MM)", "pos_numeric"]
        The function returns:
            (["Sample1", "Sample2"], ["Sample1 (PM+1MM+2MM)", "Sample2 (PM+1MM+2MM)"])
    """
    all_cols = df.columns.tolist()
    # Exclude id columns and the position column
    candidate_cols = [col for col in all_cols if col not in id_cols and col != pos_col]

    # Read columns: those that do NOT contain the total_suffix.
    read_cols = [col for col in candidate_cols if total_suffix not in col]
    # Total columns: those that contain the total_suffix.
    total_cols = [col for col in candidate_cols if total_suffix in col]

    return read_cols, total_cols

def remove_substring_in_columns(df, substring="_derived"):
    """
    Retorna un nuevo DataFrame donde, en cada columna que contenga `substring`,
    se elimina ese substring del nombre de la columna.

    Parámetros:
        df (pd.DataFrame): DataFrame original.
        substring (str): Substring a remover de los nombres de columna (default: "_derived").

    Retorna:
        pd.DataFrame: Copia del DataFrame con columnas renombradas.

    Ejemplo:
        df_clean = remove_substring_in_columns(df, substring="_derived")
    """
    # Crear un diccionario {col_viejo: col_nuevo} para las columnas que contengan substring
    rename_map = {}
    for col in df.columns:
        if substring in col:
            rename_map[col] = col.replace(substring, "")

    # Renombrar columnas usando rename_map
    df_renamed = df.rename(columns=rename_map).copy()
    return df_renamed

def remove_snvs_exceeding_frequency_threshold(
    df,
    threshold=5.0,
    id_cols=["miRNA name", "pos:mut"],
    total_suffix=" (PM+1MM+2MM)"
):
    """
    Removes rows (SNVs) if, for any sample, the frequency of that SNV
    exceeds the specified threshold. The frequency for each sample is
    calculated as:

        (read_count / total_count) * 100

    where 'read_count' is the value in the sample column, and 'total_count'
    is the value in the corresponding sample column + total_suffix.

    Parameters:
        df (pd.DataFrame):
            The input DataFrame containing:
              - Identifier columns (e.g., "miRNA name", "pos:mut").
              - Raw read count columns for each sample (e.g., "Sample1").
              - Matching total columns with the same name + total_suffix
                (e.g., "Sample1 (PM+1MM+2MM)").
        threshold (float):
            Rows are removed if ANY sample frequency exceeds this value
            (default = 5.0).
        id_cols (list):
            Columns to exclude from the frequency calculation
            (default = ["miRNA name", "pos:mut"]).
        total_suffix (str):
            The suffix that identifies total columns
            (default = " (PM+1MM+2MM)").

    Returns:
        pd.DataFrame:
            A new DataFrame with rows removed if they exceed the
            frequency threshold for any sample.

    Example usage:
        df_clean = remove_snvs_exceeding_frequency_threshold(df, threshold=5.0)
        # Now df_clean has no SNVs that exceed 5% in any sample.
    """
    # Work on a copy so we don't modify the original DataFrame
    df_copy = df.copy()

    # Identify sample columns that are not in id_cols and do not contain the total_suffix
    all_cols = df_copy.columns.tolist()
    sample_cols = [
        c for c in all_cols
        if c not in id_cols and total_suffix not in c
    ]

    if not sample_cols:
        print("No sample columns found. Please check your DataFrame structure.")
        return df_copy

    # We'll create a boolean mask for each row to see if it should be removed
    # Start with a mask of False meaning "no frequency above threshold"
    remove_mask = pd.Series(False, index=df_copy.index)

    for read_col in sample_cols:
        # The total column for this sample is read_col + total_suffix
        total_col = read_col + total_suffix
        if total_col in df_copy.columns:
            # Calculate frequency for this sample
            freq = (df_copy[read_col] / df_copy[total_col]) * 100

            # Update the remove_mask for rows that exceed threshold
            remove_mask |= (freq > threshold)
        else:
            # If there's no matching total column, we skip
            # or optionally raise a warning
            print(f"Warning: No matching total column found for '{read_col}' (expected '{total_col}'). Skipping.")

    # Filter out rows where remove_mask is True (meaning freq > threshold in at least one sample)
    df_filtered = df_copy[~remove_mask].copy()

    return df_filtered

def plot_mutated_reads_histogram(df,
                                 position_col="pos_numeric",
                                 id_cols=["miRNA name", "pos:mut", "pos_numeric"],
                                 total_suffix=" (PM+1MM+2MM)",
                                 figsize=(10,4),
                                 title="Mutated Reads per Position"):
    """
    Creates a grouped bar chart showing the mutated read counts per position,
    distinguishing each sample by color.
    All columns not in id_cols and that do not contain total_suffix are considered as read count columns.
    """
    # Select columns that contain read counts (samples)
    all_cols = df.columns.tolist()
    candidate_cols = [col for col in all_cols if col not in id_cols and total_suffix not in col]

    if not candidate_cols:
        print("No read count columns found.")
        return None, None

    # Convert the DataFrame from wide to long format, keeping the position column as the identifier
    df_melted = df.melt(id_vars=[position_col], value_vars=candidate_cols,
                        var_name="sample", value_name="read_count")

    # If there are duplicates for the same position and sample, sum the counts
    df_grouped = df_melted.groupby([position_col, "sample"], as_index=False)["read_count"].sum()

    # Create the grouped bar chart
    fig, ax = plt.subplots(figsize=figsize)
    sns.barplot(x=position_col, y="read_count", hue="sample", data=df_grouped, ax=ax)
    ax.set_xlabel("Position")
    ax.set_ylabel("Mutated Reads")
    ax.set_title(title)
    plt.tight_layout()
    plt.show()
    return fig, ax

def plot_position_vs_sample_heatmap(df,
                                    pos_col="pos_numeric",
                                    id_cols=["miRNA name", "pos:mut", "pos_numeric"],
                                    total_suffix=" (PM+1MM+2MM)",
                                    fill_value=0,
                                    figsize=(10, 6),
                                    cmap="Reds",
                                    title="Position x Sample Heatmap (Raw Counts)"):
    """
    Generates a heatmap showing:
      - Rows: Positions (from pos_col)
      - Columns: Samples (raw read count columns)
      - Color: Sum of raw reads for each (position, sample) combination.
    """
    df_copy = df.copy()
    # Select raw read count columns
    all_cols = df_copy.columns.tolist()
    candidate_cols = [col for col in all_cols if col not in id_cols and total_suffix not in col]

    if not candidate_cols:
        print("No read count columns found.")
        return None, None

    # Convert wide format to long format
    df_melt = df_copy.melt(
        id_vars=[pos_col],
        value_vars=candidate_cols,
        var_name="sample",
        value_name="reads"
    )
    # Group by position and sample
    grouped = df_melt.groupby([pos_col, "sample"])["reads"].sum().reset_index()
    # Pivot to create a matrix for the heatmap
    pivot_df = grouped.pivot(index=pos_col, columns="sample", values="reads").fillna(fill_value)
    pivot_df.sort_index(axis=0, inplace=True)
    pivot_df.sort_index(axis=1, inplace=True)

    # Plot the heatmap
    fig, ax = plt.subplots(figsize=figsize)
    sns.heatmap(pivot_df, cmap=cmap, ax=ax, cbar_kws={"label": "Sum of Raw Reads"})
    ax.set_xlabel("Sample")
    ax.set_ylabel("Position")
    ax.set_title(title)
    plt.tight_layout()
    plt.show()
    return fig, ax

def plot_g_mutations_rank(df,
                          id_cols=["miRNA name", "pos:mut", "pos_numeric"],
                          total_suffix=" (PM+1MM+2MM)",
                          mutation_col="pos:mut",
                          top_n=100,
                          figsize=(6,4),
                          title="Ranked G->X Mutations"):
    """
    Creates a plot showing the cumulative fraction of G->X mutations (X ∈ {A, C, T})
    among the top SNVs (by combined raw read counts). It filters for rows where the mutation,
    given in mutation_col, is in the format "number:GX" (e.g., "11:GT").
    """
    df_copy = df.copy()

    # Filter rows where mutation is G->A, G->C or G->T
    df_g = []
    for idx, row in df_copy.iterrows():
        val = row.get(mutation_col, "")
        if isinstance(val, str) and ":" in val:
            mut = val.split(":")[1]  # e.g. "GT"
            if len(mut) == 2:
                from_b, to_b = mut[0], mut[1]
                if from_b == "G" and to_b in ["A", "C", "T"]:
                    df_g.append(row)
    df_g = pd.DataFrame(df_g)
    if df_g.empty:
        print("No rows found with G->A, G->C, or G->T mutations.")
        return None, None

    # Select raw read count columns
    all_cols = df_g.columns.tolist()
    read_cols = [col for col in all_cols if col not in id_cols and total_suffix not in col]
    if not read_cols:
        print("No read count columns found.")
        return None, None

    # Sum the read counts and record the mutation type
    mutated_rows = []
    for idx, row in df_g.iterrows():
        val = row[mutation_col]
        mut_str = val.split(":")[1]  # e.g., "GT"
        from_b, to_b = mut_str[0], mut_str[1]
        row_sum = row[read_cols].sum(skipna=True)
        mutated_rows.append({
            "mutation_type": f"G->{to_b}",
            "combined_reads": row_sum
        })
    df_mut = pd.DataFrame(mutated_rows)
    df_mut.sort_values(by="combined_reads", ascending=False, inplace=True)
    df_mut = df_mut.head(top_n)

    if df_mut.empty:
        print("No data left after filtering to top_n.")
        return None, None

    # Add rank column
    df_mut["rank"] = range(1, len(df_mut) + 1)

    # Calculate cumulative fraction for each mutation type
    partial_sum = {"G->T": 0, "G->C": 0, "G->A": 0}
    partial_sum_total = 0
    ranks, frac_gt, frac_gc, frac_ga = [], [], [], []

    for i, row in df_mut.iterrows():
        mtype = row["mutation_type"]
        reads_val = row["combined_reads"]
        partial_sum[mtype] += reads_val
        partial_sum_total += reads_val
        r = row["rank"]
        ranks.append(r)
        if partial_sum_total > 0:
            frac_gt.append(partial_sum["G->T"] / partial_sum_total)
            frac_gc.append(partial_sum["G->C"] / partial_sum_total)
            frac_ga.append(partial_sum["G->A"] / partial_sum_total)
        else:
            frac_gt.append(0)
            frac_gc.append(0)
            frac_ga.append(0)

    # Plot the cumulative fractions
    fig, ax = plt.subplots(figsize=figsize)
    ax.plot(ranks, frac_gt, color="red", label="G->T")
    ax.plot(ranks, frac_gc, color="purple", label="G->C")
    ax.plot(ranks, frac_ga, color="blue", label="G->A")
    ax.set_xlabel("Rank")
    ax.set_ylabel("Fraction among G->X")
    ax.set_title(title)
    ax.legend()
    plt.tight_layout()
    plt.show()
    return fig, ax

def plot_top_snvs_and_distribution_freq(df,
                                          id_cols=["miRNA name", "pos:mut", "pos_numeric"],
                                          normalized_suffix=" (mm%)",
                                          top_n=30,
                                          figsize=(12, 5),
                                          title="Top SNVs and Distribution (Frequency)",
                                          exclude_pm=True):
    """
    Plots two charts:
      1. A bar chart of the top_n SNVs (by combined normalized frequency) identified by "miRNA name" and "pos:mut".
      2. A boxplot of the overall distribution of combined frequencies for all SNVs.

    It assumes that frequency columns end with normalized_suffix.
    """
    df_copy = df.copy()
    if exclude_pm:
        df_copy = df_copy[df_copy["pos:mut"] != "PM"]

    # Create a unique SNV identifier
    df_copy["snv_id"] = df_copy["miRNA name"].astype(str) + "_" + df_copy["pos:mut"].astype(str)

    all_cols = df_copy.columns.tolist()
    freq_cols = [col for col in all_cols if col not in id_cols and col.endswith(normalized_suffix)]
    if not freq_cols:
        print("No frequency columns found. Check that they have the normalized suffix.")
        return None, (None, None)

    # Calculate the combined frequency for each row
    df_copy["combined_freq"] = df_copy[freq_cols].sum(axis=1, skipna=True)
    df_sorted = df_copy.sort_values(by="combined_freq", ascending=False).copy()
    df_top = df_sorted.head(top_n)

    # Create a figure with two subplots
    fig, (ax_bar, ax_box) = plt.subplots(ncols=2, figsize=figsize)
    fig.suptitle(title, fontsize=14)

    sns.barplot(x="snv_id", y="combined_freq", data=df_top, ax=ax_bar, color="skyblue")
    ax_bar.set_xlabel("SNV (miRNA name + pos:mut)")
    ax_bar.set_ylabel("Combined Frequency (%)")
    ax_bar.set_title(f"Top {top_n} SNVs")
    ax_bar.tick_params(axis="x", rotation=90)

    sns.boxplot(x=df_sorted["combined_freq"], ax=ax_box, color="lightgray")
    ax_box.set_xlabel("Combined Frequency (%)")
    ax_box.set_title("Distribution (All SNVs)")

    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()
    return fig, (ax_bar, ax_box)

def plot_top_snvs_and_distribution_freq_and_total_reads(
    df,
    id_cols=["miRNA name", "pos:mut", "pos_numeric"],
    normalized_suffix=" (mm%)",
    total_suffix=" (PM+1MM+2MM)",
    top_n=30,
    figsize=(16, 10),
    title="Top SNVs and Distribution (Frequency & Total Reads)",
    exclude_pm=True
):
    """
    Plots four charts in a 2x2 grid:
      1. Bar plot of top_n SNVs by combined normalized frequency.
      2. Boxplot of the overall frequency distribution for all SNVs.
      3. Bar plot of the average total reads (from total columns) for the top_n SNVs.
      4. Boxplot of the overall distribution of average total reads for all SNVs.

    It assumes that:
      - Frequency columns end with `normalized_suffix` (e.g., " (mm%)").
      - Total read columns contain `total_suffix` (e.g., " (PM+1MM+2MM)").
      - The DataFrame has identifier columns as specified in id_cols.

    This function is useful when SNVs are nearly 100% represented across samples, so
    the average total reads provide a good summary of their abundance.
    """
    df_copy = df.copy()

    # Optionally exclude rows with perfect match "PM"
    if exclude_pm:
        df_copy = df_copy[df_copy["pos:mut"] != "PM"]

    # Create a unique SNV identifier
    df_copy["snv_id"] = df_copy["miRNA name"].astype(str) + "_" + df_copy["pos:mut"].astype(str)

    # Frequency part:
    freq_cols = [col for col in df_copy.columns if col not in id_cols and col.endswith(normalized_suffix)]
    if not freq_cols:
        print("No frequency columns found. Check that they have the normalized suffix.")
        return None, None
    df_copy["combined_freq"] = df_copy[freq_cols].sum(axis=1, skipna=True)

    # Total reads part:
    total_cols = [col for col in df_copy.columns if col not in id_cols and total_suffix in col]
    if not total_cols:
        print("No total read columns found. Check that they contain the expected total suffix.")
        return None, None
    # Compute the average total reads for each SNV across the total columns
    df_copy["avg_total_reads"] = df_copy[total_cols].mean(axis=1)

    # Sort the DataFrame by combined frequency
    df_sorted = df_copy.sort_values(by="combined_freq", ascending=False).copy()
    df_top = df_sorted.head(top_n)

    # Create a 2x2 figure
    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=figsize)
    (ax_bar_freq, ax_box_freq), (ax_bar_total, ax_box_total) = axes

    # Top-left: Bar plot of top SNVs by frequency
    sns.barplot(x="snv_id", y="combined_freq", data=df_top, ax=ax_bar_freq, color="skyblue")
    ax_bar_freq.set_xlabel("SNV (miRNA name + pos:mut)")
    ax_bar_freq.set_ylabel("Combined Frequency (%)")
    ax_bar_freq.set_title(f"Top {top_n} SNVs (Frequency)")
    ax_bar_freq.tick_params(axis="x", rotation=90)

    # Top-right: Boxplot of overall frequency distribution
    sns.boxplot(x=df_sorted["combined_freq"], ax=ax_box_freq, color="lightgray")
    ax_box_freq.set_xlabel("Combined Frequency (%)")
    ax_box_freq.set_title("Frequency Distribution (All SNVs)")

    # Bottom-left: Bar plot of top SNVs by average total reads
    sns.barplot(x="snv_id", y="avg_total_reads", data=df_top, ax=ax_bar_total, color="skyblue")
    ax_bar_total.set_xlabel("SNV (miRNA name + pos:mut)")
    ax_bar_total.set_ylabel("Average Total Reads")
    ax_bar_total.set_title(f"Top {top_n} SNVs (Total Reads)")
    ax_bar_total.tick_params(axis="x", rotation=90)

    # Bottom-right: Boxplot of overall average total reads distribution
    sns.boxplot(x=df_sorted["avg_total_reads"], ax=ax_box_total, color="lightgray")
    ax_box_total.set_xlabel("Average Total Reads")
    ax_box_total.set_title("Total Reads Distribution (All SNVs)")

    plt.suptitle(title, fontsize=16)
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()

    return fig, axes



def pca_samples_and_plot_by_condition(
    df,
    id_cols=["miRNA name", "pos:mut", "pos_numeric"],
    total_suffix=" (PM+1MM+2MM)",
    n_components=2,
    scale_data=True,
    condition_func=None,
    title="PCA of Samples"
):
    """
    Performs PCA considering each sample as an observation (transposing the data).
    By default, samples are colored based on whether their name contains 'SOD1' or 'TDP43',
    otherwise labeled as 'control'. You can override this behavior by providing a custom
    'condition_func'.

    Parameters:
      df (pd.DataFrame): The input DataFrame.
      id_cols (list): Columns to exclude as identifiers (e.g. "miRNA name", "pos:mut", "pos_numeric").
      total_suffix (str): Suffix identifying total columns (e.g. " (PM+1MM+2MM)").
      n_components (int): Number of principal components to compute (default 2 for a 2D plot).
      scale_data (bool): Whether to scale (standardize) the data before PCA (default True).
      condition_func (callable): A function that takes a sample_name (str) and returns a group label (str).
                                 If None, uses a default function that checks for 'SOD1', 'TDP43', or else 'control'.
      title (str): Title of the PCA scatter plot.

    Returns:
      tuple: (pca, df_pca) where:
         - pca is the fitted PCA object (from scikit-learn).
         - df_pca is a DataFrame with one row per sample, columns for principal components (PC1, PC2, ...)
           and a 'Condition' column indicating the group label.
    """

    # 1. Identify the sample columns (exclude id_cols and total_suffix).
    sample_cols = [col for col in df.columns if col not in id_cols and total_suffix not in col]
    if not sample_cols:
        print("No numeric sample columns found for PCA. Check the DataFrame structure.")
        return None, None

    # 2. Transpose so that each row is a sample, each column is a feature (SNV).
    #    shape => (#samples, #SNVs).
    data_for_pca = df[sample_cols].T

    # 3. Optionally scale (standardize) the data: each feature (SNV) gets mean=0, std=1.
    if scale_data:
        scaler = StandardScaler()
        data_scaled = scaler.fit_transform(data_for_pca)
    else:
        data_scaled = data_for_pca.values

    # 4. Perform PCA on the transposed data.
    pca = PCA(n_components=n_components)
    principal_components = pca.fit_transform(data_scaled)

    # 5. Build a DataFrame with the principal components; index = sample names.
    comp_names = [f"PC{i+1}" for i in range(n_components)]
    df_pca = pd.DataFrame(principal_components, columns=comp_names, index=data_for_pca.index)

    # 6. Default condition function (SOD1 / TDP43 / control) if none is provided.
    def default_condition_func(sample_name: str) -> str:
        name_lower = sample_name.lower()
        if "sod1" in name_lower:
            return "SOD1"
        elif "tdp43" in name_lower:
            return "TDP43"
        else:
            return "control"

    if condition_func is None:
        condition_func = default_condition_func

    # 7. Apply the condition function to each sample name to determine grouping.
    df_pca["Condition"] = df_pca.index.map(condition_func)

    # 8. Print explained variance ratio for each principal component.
    print("Explained Variance Ratio:")
    for i, ratio in enumerate(pca.explained_variance_ratio_):
        print(f"  PC{i+1}: {ratio:.3f}")

    # 9. Plot PC1 vs PC2, coloring by Condition.
    plt.figure(figsize=(8, 6))
    sns.scatterplot(
        x="PC1",
        y="PC2",
        hue="Condition",
        data=df_pca,
        palette="Set1",
        s=100
    )
    plt.title(title)
    plt.xlabel("Principal Component 1")
    plt.ylabel("Principal Component 2")
    plt.tight_layout()
    plt.show()

    return pca, df_pca

def plot_mutated_reads_histograms_v2(df,
                                 position_col="pos_numeric",
                                 id_cols=["miRNA name", "pos:mut", "pos_numeric"],
                                 total_suffix=" (PM+1MM+2MM)",
                                 figsize=(10,4),
                                 title="Mutated Reads per Position"):
    """
    Crea un gráfico de barras agrupado que muestra la cantidad de lecturas mutadas por posición,
    distinguiendo cada muestra por color.
    Todas las columnas que no estén en id_cols y que no contengan total_suffix se consideran
    columnas de conteo (muestras).

    Además, devuelve un DataFrame 'df_summary_sorted' con las columnas:
       ['miRNA name', 'pos:mut', 'pos_numeric', 'sample', 'read_count']
    ordenado según la cantidad de lecturas mutadas.
    """
    # 1. Seleccionar columnas de conteo (muestras)
    all_cols = df.columns.tolist()
    candidate_cols = [col for col in all_cols if col not in id_cols and total_suffix not in col]

    if not candidate_cols:
        print("No se encontraron columnas de conteo de lecturas.")
        return None, None, None

    # 2. Crear DataFrame resumen: se melt con id_vars incluyendo pos_numeric
    df_summary = df.melt(
        id_vars=["miRNA name", "pos:mut", position_col],
        value_vars=candidate_cols,
        var_name="sample",
        value_name="read_count"
    )
    # Agrupar para asegurarnos de que si había duplicados, se sumen
    df_summary = df_summary.groupby(["miRNA name", "pos:mut", position_col, "sample"], as_index=False)["read_count"].sum()
    # Ordenar de mayor a menor
    df_summary_sorted = df_summary.sort_values("read_count", ascending=False)

    # 3. Para la gráfica principal, necesitamos agrupar por posición y muestra
    #    Hacemos un melt específico solo para (posición, muestras) y luego sumamos
    df_melted = df.melt(
        id_vars=[position_col],
        value_vars=candidate_cols,
        var_name="sample",
        value_name="read_count"
    )
    df_grouped = df_melted.groupby([position_col, "sample"], as_index=False)["read_count"].sum()

    # 4. Crear el gráfico de barras agrupado
    fig, ax = plt.subplots(figsize=figsize)
    sns.barplot(x=position_col, y="read_count", hue="sample", data=df_grouped, ax=ax)
    ax.set_xlabel("Posición")
    ax.set_ylabel("Lecturas Mutadas")
    ax.set_title(title)
    plt.tight_layout()
    plt.show()

    return fig, ax, df_summary_sorted

def report_top_mirnas_with_snvs(df_summary, top_n=3):
    """
    Para cada (pos_numeric, sample), selecciona los top_n miRNAs
    en base a la suma total de lecturas (independientemente del número de SNVs),
    y luego muestra los detalles (todas las filas SNV) de esos miRNAs.

    Retorna un DataFrame (df_report) donde verás, para cada posición y muestra,
    los miRNAs más abundantes y cada uno de los SNVs que contribuye a ese total.
    """
    import pandas as pd

    # 1. Agrupar por (pos_numeric, sample, miRNA name) para sumar las lecturas
    df_agg = (
        df_summary
        .groupby(["pos_numeric", "sample", "miRNA name"], as_index=False)["read_count"]
        .sum()
    )

    # 2. Para cada (pos_numeric, sample), tomar los top_n miRNAs con mayor 'read_count'
    def _top(grp):
        return grp.nlargest(top_n, "read_count")

    df_top = (
        df_agg
        .groupby(["pos_numeric", "sample"], group_keys=False)
        .apply(_top)
    )

    # 3. Unir los miRNAs seleccionados con el DataFrame original para no perder el detalle de SNVs
    #    (left join con df_summary)
    df_report = pd.merge(
        df_top,  # tiene columnas: pos_numeric, sample, miRNA name, read_count (agrupado)
        df_summary,  # tiene el detalle de cada SNV
        on=["pos_numeric", "sample", "miRNA name"],
        how="left",
        suffixes=("_total", "")  # para diferenciar la col 'read_count_total' de la 'read_count' detallada
    )

    # Ordenamos un poco el resultado:
    # - Primero por posición
    # - Luego por muestra
    # - Luego por el total de lecturas (descendente)
    df_report = df_report.sort_values(
        by=["pos_numeric", "sample", "read_count_total"],
        ascending=[True, True, False]
    )

    return df_report

def plot_sample_correlation_heatmap(df, id_cols=["miRNA name", "pos:mut", "pos_numeric"], total_suffix=" (PM+1MM+2MM)", figsize=(12,10), cmap="viridis"):
    """
    Calcula y muestra un heatmap de la matriz de correlación entre las muestras.
    Se consideran todas las columnas que no sean de identificación ni contengan el sufijo total_suffix.

    Parámetros:
      df: DataFrame de entrada.
      id_cols: Columnas a excluir (por ejemplo, identificadores y posiciones).
      total_suffix: Sufijo que identifica las columnas de totales.
      figsize: Tamaño de la figura.
      cmap: Colormap para el heatmap.

    Retorna:
      La figura y el objeto Axes.
    """
    # Seleccionar columnas de muestras
    sample_cols = [col for col in df.columns if col not in id_cols and total_suffix not in col]
    if not sample_cols:
        print("No se encontraron columnas de muestra.")
        return None, None
    # Transponer: filas = muestras, columnas = features (SNVs o lecturas)
    data_samples = df[sample_cols].T
    # Calcular la matriz de correlación entre muestras
    corr_matrix = data_samples.corr()

    fig, ax = plt.subplots(figsize=figsize)
    sns.heatmap(corr_matrix, cmap=cmap, ax=ax, cbar_kws={"label": "Correlación"})
    ax.set_title("Matriz de correlación entre muestras")
    plt.tight_layout()
    plt.show()
    return fig, ax

from scipy.cluster.hierarchy import linkage, dendrogram

def plot_sample_dendrogram(df, id_cols=["miRNA name", "pos:mut", "pos_numeric"], total_suffix=" (PM+1MM+2MM)", method="average", figsize=(12, 8)):
    """
    Calcula la matriz de correlación entre muestras y muestra un dendrograma usando clustering jerárquico.

    Parámetros:
      df: DataFrame de entrada.
      id_cols: Columnas a excluir.
      total_suffix: Sufijo que identifica las columnas de totales.
      method: Método de linkage (por defecto, 'average').
      figsize: Tamaño de la figura.

    Retorna:
      La figura y el diccionario del dendrograma.
    """
    # Seleccionar columnas de muestras
    sample_cols = [col for col in df.columns if col not in id_cols and total_suffix not in col]
    if not sample_cols:
        print("No se encontraron columnas de muestra.")
        return None, None
    data_samples = df[sample_cols].T
    # Calcular la distancia: 1 - correlación
    corr_matrix = data_samples.corr()
    distance = 1 - corr_matrix
    # Vectorizar la matriz de distancia
    linked = linkage(distance, method=method)

    fig, ax = plt.subplots(figsize=figsize)
    dendrogram(linked, labels=data_samples.index, ax=ax, leaf_rotation=90)
    ax.set_title("Dendrograma de muestras")
    plt.tight_layout()
    plt.show()
    return fig, ax

def plot_grouped_distribution(df, group_func, value_col, id_cols=["miRNA name", "pos:mut", "pos_numeric"], total_suffix=" (PM+1MM+2MM)", figsize=(10,6), plot_type="box", title="Distribución de valores agrupados"):
    """
    Agrupa las muestras según una función provista (group_func) que se aplica al nombre de la columna,
    y genera un boxplot o violin plot de la distribución de valores (por ejemplo, frecuencia o lecturas).

    Parámetros:
      df: DataFrame de entrada.
      group_func: Función que, dada una cadena de nombre de muestra, retorna la categoría (por ejemplo, tratamiento).
      value_col: Columna de valor a analizar (por ejemplo, "combined_freq" o "avg_total_reads").
      id_cols: Columnas a excluir.
      total_suffix: Sufijo que identifica columnas de totales (se ignoran en esta función).
      figsize: Tamaño de la figura.
      plot_type: "box" para boxplot, "violin" para violin plot.
      title: Título del gráfico.

    Retorna:
      La figura y el objeto Axes.
    """
    # Seleccionar columnas de muestra
    sample_cols = [col for col in df.columns if col not in id_cols and total_suffix not in col]
    if not sample_cols:
        print("No se encontraron columnas de muestra.")
        return None, None

    # Creamos un DataFrame para el gráfico, extrayendo los valores de 'value_col' por muestra.
    # Suponiendo que 'value_col' ya existe en df y representa un resumen por muestra.
    # Alternativamente, podrías calcular un promedio o mediana por cada muestra.

    # Crear un DataFrame con dos columnas: sample y valor
    data_list = []
    for col in sample_cols:
        # Puedes definir cómo agrupar; por ejemplo:
        group = group_func(col)
        valor = df[col].mean()  # ejemplo: promedio de la columna
        data_list.append({"sample": col, "group": group, "value": valor})
    df_plot = pd.DataFrame(data_list)

    fig, ax = plt.subplots(figsize=figsize)
    if plot_type == "box":
        sns.boxplot(x="group", y="value", data=df_plot, ax=ax)
    elif plot_type == "violin":
        sns.violinplot(x="group", y="value", data=df_plot, ax=ax)
    else:
        print("Tipo de gráfico desconocido. Usa 'box' o 'violin'.")
        return None, None
    ax.set_title(title)
    ax.set_xlabel("Grupo")
    ax.set_ylabel("Valor")
    plt.tight_layout()
    plt.show()
    return fig, ax

df

df_cle