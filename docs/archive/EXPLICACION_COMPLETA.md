# ğŸ“š EXPLICACIÃ“N COMPLETA: Â¿QuÃ© se hizo y cÃ³mo funciona?

## ğŸ¯ Â¿QuÃ© es Snakemake?

**Snakemake** es un sistema de workflow que automatiza anÃ¡lisis cientÃ­ficos. En lugar de ejecutar scripts manualmente uno por uno, defines **reglas** que especifican:
- **QuÃ© inputs necesita** (archivos de datos)
- **QuÃ© outputs genera** (figuras, tablas)
- **CÃ³mo generarlos** (quÃ© script R ejecutar)

**Ventaja**: Snakemake ejecuta solo lo necesario, en el orden correcto, y sabe quÃ© estÃ¡ actualizado.

---

## ğŸ”„ Â¿QuÃ© se hizo? TransformaciÃ³n de Pipeline Manual â†’ Automatizado

### ANTES (Pipeline Manual):
```
Tu ejecutabas:
1. Rscript script1.R
2. Rscript script2.R
3. Rscript script3.R
...
(tenÃ­as que recordar el orden, rutas, dependencias)
```

### AHORA (Pipeline Snakemake):
```
Ejecutas:
snakemake -j 1

Snakemake:
1. Lee las reglas (quÃ© necesita cada script)
2. Calcula el orden correcto
3. Ejecuta solo lo necesario
4. Verifica que los outputs se generaron
```

---

## ğŸ“ Estructura Creada

### 1. **Snakefile** (Orquestador Principal)
```
Snakefile
â”œâ”€â”€ Carga config/config.yaml
â”œâ”€â”€ Incluye reglas de step1.smk
â”œâ”€â”€ Incluye reglas de step1_5.smk
â””â”€â”€ Define quÃ© se ejecuta por defecto (rule all)
```

**Ejemplo del Snakefile:**
```python
configfile: "config/config.yaml"  # Carga configuraciÃ³n
include: "rules/step1.smk"       # Incluye reglas del Step 1
include: "rules/step1_5.smk"     # Incluye reglas del Step 1.5

rule all:
    input:
        rules.all_step1.output,        # Todos los outputs de Step 1
        rules.all_step1_5.output      # Todos los outputs de Step 1.5
```

---

### 2. **Reglas** (`rules/*.smk`)

Cada regla define **UNA tarea** del pipeline. Por ejemplo:

**Regla para Panel B (Step 1):**
```python
rule panel_b_gt_count_by_position:
    input:
        data = "ruta/al/dato.csv",           # â† Input necesario
        functions = "scripts/utils/functions.R"
    output:
        figure = "outputs/step1/figures/panelB.png",  # â† Output que genera
        table = "outputs/step1/tables/panelB.csv"
    script:
        "scripts/step1/01_panel_b.R"         # â† Script R que ejecuta
```

**Lo que hace Snakemake:**
1. Verifica si existe `outputs/step1/figures/panelB.png`
2. Si NO existe (o si el input cambiÃ³), ejecuta el script R
3. Si SÃ existe y estÃ¡ actualizado, lo omite (no lo vuelve a generar)

---

### 3. **Scripts R Adaptados** (`scripts/step1/*.R`)

**Antes (manual):**
```r
# Rutas hardcodeadas
data <- read.csv("/Users/cesaresparza/.../datos.csv")
output_fig <- "/Users/cesaresparza/.../figura.png"
```

**Ahora (Snakemake):**
```r
# Snakemake pasa las rutas automÃ¡ticamente
input_file <- snakemake@input[["data"]]
output_fig <- snakemake@output[["figure"]]

data <- read.csv(input_file)
# ... anÃ¡lisis ...
ggsave(output_fig, plot, ...)
```

**Ventaja**: Mismo script, pero ahora recibe las rutas automÃ¡ticamente.

---

### 4. **ConfiguraciÃ³n Centralizada** (`config/config.yaml`)

**Antes**: Rutas hardcodeadas en cada script.

**Ahora**: Todo en un solo archivo:
```yaml
paths:
  data:
    processed_clean: "/ruta/a/datos/procesados.csv"
    step1_original: "/ruta/a/datos/originales.csv"
  
analysis:
  vaf_filter_threshold: 0.5
  colors:
    gt: "#D62728"  # Rojo para G>T
```

**Ventaja**: Cambias las rutas una vez, todo el pipeline se actualiza.

---

### 5. **Environment Conda** (`environment.yaml`)

Define todas las dependencias (R, paquetes R, Python, Snakemake):

```yaml
name: als_mirna_pipeline
dependencies:
  - python=3.10
  - snakemake=7.32
  - r-base=4.3.2
  - r-tidyverse
  - r-ggplot2
  ...
```

**Ventaja**: Otro usuario puede recrear el ambiente exacto con:
```bash
conda env create -f environment.yaml
```

---

## ğŸ”„ Flujo de EjecuciÃ³n (Ejemplo: Step 1)

### Cuando ejecutas `snakemake -j 1`:

1. **Snakemake lee `Snakefile`**
   - Carga `config.yaml`
   - Incluye `rules/step1.smk`

2. **Snakemake construye el "grafo de dependencias"**
   ```
   all_step1 necesita:
     â”œâ”€ panelB.png (requiere datos + script panelB.R)
     â”œâ”€ panelC.png (requiere datos + script panelC.R)
     â””â”€ panelD.png (requiere datos + script panelD.R)
     ...
   ```

3. **Snakemake decide quÃ© ejecutar**
   - Si `panelB.png` NO existe â†’ ejecuta `panelB.R`
   - Si `panelB.png` existe pero es mÃ¡s viejo que los inputs â†’ re-ejecuta
   - Si estÃ¡ actualizado â†’ omite (ahorra tiempo)

4. **Snakemake ejecuta en paralelo (si es posible)**
   - `panelB` y `panelC` pueden ejecutarse simultÃ¡neamente (no dependen uno del otro)
   - Pero `panelC` NO puede ejecutarse antes de cargar los datos

5. **Snakemake verifica outputs**
   - Si algÃºn script falla, Snakemake se detiene
   - Si todo funciona, marca `all_step1` como completado

---

## ğŸ“Š Ejemplo Real: Paso 1.5

### Reglas definidas:

**Regla 1: `apply_vaf_filter`**
```python
Input:  step1_original_data.csv
Output: ALL_MUTATIONS_VAF_FILTERED.csv
        vaf_filter_report.csv
        vaf_statistics_by_type.csv
        vaf_statistics_by_mirna.csv
Script: 01_apply_vaf_filter.R
```

**Regla 2: `generate_diagnostic_figures`**
```python
Input:  (depende de Regla 1) â†’ necesita los 4 CSVs de arriba
Output: 11 figuras PNG + 3 tablas CSV
Script: 02_generate_diagnostic_figures.R
```

**Regla 3: `all_step1_5`** (agregador)
```python
Input:  Todas las salidas de Regla 1 + Regla 2
Output: (ninguno nuevo, solo verifica que todo existe)
```

**EjecuciÃ³n:**
```
snakemake -j 1 all_step1_5
  â†“
1. Ejecuta apply_vaf_filter â†’ genera 4 CSVs
  â†“
2. Ejecuta generate_diagnostic_figures â†’ genera 11 PNGs + 3 CSVs
  â†“
3. Verifica que todos los outputs existen â†’ âœ… COMPLETO
```

---

## ğŸ¯ Ventajas del Pipeline Automatizado

1. **Reproducible**: Otro usuario puede ejecutar exactamente lo mismo
2. **Eficiente**: Solo ejecuta lo que falta o cambiÃ³
3. **Orden correcto**: Respeta dependencias automÃ¡ticamente
4. **Configurable**: Rutas y parÃ¡metros en un solo lugar
5. **Escalable**: FÃ¡cil agregar nuevos pasos (solo agregar reglas)

---

## ğŸš€ CÃ³mo se Usa Ahora

```bash
# 1. Crear ambiente (una vez)
conda env create -f environment.yaml
conda activate als_mirna_pipeline

# 2. Configurar rutas (una vez)
# Editar config/config.yaml

# 3. Ejecutar (siempre)
snakemake -j 1              # Todo el pipeline
snakemake -j 1 all_step1    # Solo Step 1
snakemake -n                # Ver quÃ© se ejecutarÃ­a (dry-run)
```

---

## ğŸ“ Resumen de Archivos Creados/Modificados

### Nuevos archivos Snakemake:
- âœ… `Snakefile` - Orquestador principal
- âœ… `rules/step1.smk` - Reglas del Step 1
- âœ… `rules/step1_5.smk` - Reglas del Step 1.5
- âœ… `rules/viewers.smk` - Reglas para generar viewers HTML
- âœ… `config/config.yaml` - ConfiguraciÃ³n centralizada
- âœ… `environment.yaml` - Ambiente conda completo
- âœ… `.gitignore` - Para GitHub
- âœ… `README.md` - Instrucciones de uso

### Scripts R adaptados:
- âœ… `scripts/step1/*.R` - 6 scripts adaptados
- âœ… `scripts/step1_5/*.R` - 2 scripts adaptados
- âœ… `scripts/utils/*.R` - Funciones comunes y builders de viewers

### Estructura de outputs:
- âœ… `outputs/step1/` - Figuras, tablas, logs del Step 1
- âœ… `outputs/step1_5/` - Figuras, tablas, logs del Step 1.5
- âœ… `viewers/` - Viewers HTML generados automÃ¡ticamente

---

## ğŸ“ ConclusiÃ³n

**Lo que tenÃ­as**: Scripts R independientes que ejecutabas manualmente.

**Lo que tienes ahora**: Un pipeline automatizado que:
- Se ejecuta con un comando
- Maneja dependencias automÃ¡ticamente
- Es reproducible y portable
- EstÃ¡ listo para GitHub
- Puede usarse como herramienta por otros usuarios

**Complejidad agregada**: MÃ­nima (solo aprendes la sintaxis de Snakemake)
**Beneficio obtenido**: MÃ¡ximo (automatizaciÃ³n completa)


## ğŸ¯ Â¿QuÃ© es Snakemake?

**Snakemake** es un sistema de workflow que automatiza anÃ¡lisis cientÃ­ficos. En lugar de ejecutar scripts manualmente uno por uno, defines **reglas** que especifican:
- **QuÃ© inputs necesita** (archivos de datos)
- **QuÃ© outputs genera** (figuras, tablas)
- **CÃ³mo generarlos** (quÃ© script R ejecutar)

**Ventaja**: Snakemake ejecuta solo lo necesario, en el orden correcto, y sabe quÃ© estÃ¡ actualizado.

---

## ğŸ”„ Â¿QuÃ© se hizo? TransformaciÃ³n de Pipeline Manual â†’ Automatizado

### ANTES (Pipeline Manual):
```
Tu ejecutabas:
1. Rscript script1.R
2. Rscript script2.R
3. Rscript script3.R
...
(tenÃ­as que recordar el orden, rutas, dependencias)
```

### AHORA (Pipeline Snakemake):
```
Ejecutas:
snakemake -j 1

Snakemake:
1. Lee las reglas (quÃ© necesita cada script)
2. Calcula el orden correcto
3. Ejecuta solo lo necesario
4. Verifica que los outputs se generaron
```

---

## ğŸ“ Estructura Creada

### 1. **Snakefile** (Orquestador Principal)
```
Snakefile
â”œâ”€â”€ Carga config/config.yaml
â”œâ”€â”€ Incluye reglas de step1.smk
â”œâ”€â”€ Incluye reglas de step1_5.smk
â””â”€â”€ Define quÃ© se ejecuta por defecto (rule all)
```

**Ejemplo del Snakefile:**
```python
configfile: "config/config.yaml"  # Carga configuraciÃ³n
include: "rules/step1.smk"       # Incluye reglas del Step 1
include: "rules/step1_5.smk"     # Incluye reglas del Step 1.5

rule all:
    input:
        rules.all_step1.output,        # Todos los outputs de Step 1
        rules.all_step1_5.output      # Todos los outputs de Step 1.5
```

---

### 2. **Reglas** (`rules/*.smk`)

Cada regla define **UNA tarea** del pipeline. Por ejemplo:

**Regla para Panel B (Step 1):**
```python
rule panel_b_gt_count_by_position:
    input:
        data = "ruta/al/dato.csv",           # â† Input necesario
        functions = "scripts/utils/functions.R"
    output:
        figure = "outputs/step1/figures/panelB.png",  # â† Output que genera
        table = "outputs/step1/tables/panelB.csv"
    script:
        "scripts/step1/01_panel_b.R"         # â† Script R que ejecuta
```

**Lo que hace Snakemake:**
1. Verifica si existe `outputs/step1/figures/panelB.png`
2. Si NO existe (o si el input cambiÃ³), ejecuta el script R
3. Si SÃ existe y estÃ¡ actualizado, lo omite (no lo vuelve a generar)

---

### 3. **Scripts R Adaptados** (`scripts/step1/*.R`)

**Antes (manual):**
```r
# Rutas hardcodeadas
data <- read.csv("/Users/cesaresparza/.../datos.csv")
output_fig <- "/Users/cesaresparza/.../figura.png"
```

**Ahora (Snakemake):**
```r
# Snakemake pasa las rutas automÃ¡ticamente
input_file <- snakemake@input[["data"]]
output_fig <- snakemake@output[["figure"]]

data <- read.csv(input_file)
# ... anÃ¡lisis ...
ggsave(output_fig, plot, ...)
```

**Ventaja**: Mismo script, pero ahora recibe las rutas automÃ¡ticamente.

---

### 4. **ConfiguraciÃ³n Centralizada** (`config/config.yaml`)

**Antes**: Rutas hardcodeadas en cada script.

**Ahora**: Todo en un solo archivo:
```yaml
paths:
  data:
    processed_clean: "/ruta/a/datos/procesados.csv"
    step1_original: "/ruta/a/datos/originales.csv"
  
analysis:
  vaf_filter_threshold: 0.5
  colors:
    gt: "#D62728"  # Rojo para G>T
```

**Ventaja**: Cambias las rutas una vez, todo el pipeline se actualiza.

---

### 5. **Environment Conda** (`environment.yaml`)

Define todas las dependencias (R, paquetes R, Python, Snakemake):

```yaml
name: als_mirna_pipeline
dependencies:
  - python=3.10
  - snakemake=7.32
  - r-base=4.3.2
  - r-tidyverse
  - r-ggplot2
  ...
```

**Ventaja**: Otro usuario puede recrear el ambiente exacto con:
```bash
conda env create -f environment.yaml
```

---

## ğŸ”„ Flujo de EjecuciÃ³n (Ejemplo: Step 1)

### Cuando ejecutas `snakemake -j 1`:

1. **Snakemake lee `Snakefile`**
   - Carga `config.yaml`
   - Incluye `rules/step1.smk`

2. **Snakemake construye el "grafo de dependencias"**
   ```
   all_step1 necesita:
     â”œâ”€ panelB.png (requiere datos + script panelB.R)
     â”œâ”€ panelC.png (requiere datos + script panelC.R)
     â””â”€ panelD.png (requiere datos + script panelD.R)
     ...
   ```

3. **Snakemake decide quÃ© ejecutar**
   - Si `panelB.png` NO existe â†’ ejecuta `panelB.R`
   - Si `panelB.png` existe pero es mÃ¡s viejo que los inputs â†’ re-ejecuta
   - Si estÃ¡ actualizado â†’ omite (ahorra tiempo)

4. **Snakemake ejecuta en paralelo (si es posible)**
   - `panelB` y `panelC` pueden ejecutarse simultÃ¡neamente (no dependen uno del otro)
   - Pero `panelC` NO puede ejecutarse antes de cargar los datos

5. **Snakemake verifica outputs**
   - Si algÃºn script falla, Snakemake se detiene
   - Si todo funciona, marca `all_step1` como completado

---

## ğŸ“Š Ejemplo Real: Paso 1.5

### Reglas definidas:

**Regla 1: `apply_vaf_filter`**
```python
Input:  step1_original_data.csv
Output: ALL_MUTATIONS_VAF_FILTERED.csv
        vaf_filter_report.csv
        vaf_statistics_by_type.csv
        vaf_statistics_by_mirna.csv
Script: 01_apply_vaf_filter.R
```

**Regla 2: `generate_diagnostic_figures`**
```python
Input:  (depende de Regla 1) â†’ necesita los 4 CSVs de arriba
Output: 11 figuras PNG + 3 tablas CSV
Script: 02_generate_diagnostic_figures.R
```

**Regla 3: `all_step1_5`** (agregador)
```python
Input:  Todas las salidas de Regla 1 + Regla 2
Output: (ninguno nuevo, solo verifica que todo existe)
```

**EjecuciÃ³n:**
```
snakemake -j 1 all_step1_5
  â†“
1. Ejecuta apply_vaf_filter â†’ genera 4 CSVs
  â†“
2. Ejecuta generate_diagnostic_figures â†’ genera 11 PNGs + 3 CSVs
  â†“
3. Verifica que todos los outputs existen â†’ âœ… COMPLETO
```

---

## ğŸ¯ Ventajas del Pipeline Automatizado

1. **Reproducible**: Otro usuario puede ejecutar exactamente lo mismo
2. **Eficiente**: Solo ejecuta lo que falta o cambiÃ³
3. **Orden correcto**: Respeta dependencias automÃ¡ticamente
4. **Configurable**: Rutas y parÃ¡metros en un solo lugar
5. **Escalable**: FÃ¡cil agregar nuevos pasos (solo agregar reglas)

---

## ğŸš€ CÃ³mo se Usa Ahora

```bash
# 1. Crear ambiente (una vez)
conda env create -f environment.yaml
conda activate als_mirna_pipeline

# 2. Configurar rutas (una vez)
# Editar config/config.yaml

# 3. Ejecutar (siempre)
snakemake -j 1              # Todo el pipeline
snakemake -j 1 all_step1    # Solo Step 1
snakemake -n                # Ver quÃ© se ejecutarÃ­a (dry-run)
```

---

## ğŸ“ Resumen de Archivos Creados/Modificados

### Nuevos archivos Snakemake:
- âœ… `Snakefile` - Orquestador principal
- âœ… `rules/step1.smk` - Reglas del Step 1
- âœ… `rules/step1_5.smk` - Reglas del Step 1.5
- âœ… `rules/viewers.smk` - Reglas para generar viewers HTML
- âœ… `config/config.yaml` - ConfiguraciÃ³n centralizada
- âœ… `environment.yaml` - Ambiente conda completo
- âœ… `.gitignore` - Para GitHub
- âœ… `README.md` - Instrucciones de uso

### Scripts R adaptados:
- âœ… `scripts/step1/*.R` - 6 scripts adaptados
- âœ… `scripts/step1_5/*.R` - 2 scripts adaptados
- âœ… `scripts/utils/*.R` - Funciones comunes y builders de viewers

### Estructura de outputs:
- âœ… `outputs/step1/` - Figuras, tablas, logs del Step 1
- âœ… `outputs/step1_5/` - Figuras, tablas, logs del Step 1.5
- âœ… `viewers/` - Viewers HTML generados automÃ¡ticamente

---

## ğŸ“ ConclusiÃ³n

**Lo que tenÃ­as**: Scripts R independientes que ejecutabas manualmente.

**Lo que tienes ahora**: Un pipeline automatizado que:
- Se ejecuta con un comando
- Maneja dependencias automÃ¡ticamente
- Es reproducible y portable
- EstÃ¡ listo para GitHub
- Puede usarse como herramienta por otros usuarios

**Complejidad agregada**: MÃ­nima (solo aprendes la sintaxis de Snakemake)
**Beneficio obtenido**: MÃ¡ximo (automatizaciÃ³n completa)


## ğŸ¯ Â¿QuÃ© es Snakemake?

**Snakemake** es un sistema de workflow que automatiza anÃ¡lisis cientÃ­ficos. En lugar de ejecutar scripts manualmente uno por uno, defines **reglas** que especifican:
- **QuÃ© inputs necesita** (archivos de datos)
- **QuÃ© outputs genera** (figuras, tablas)
- **CÃ³mo generarlos** (quÃ© script R ejecutar)

**Ventaja**: Snakemake ejecuta solo lo necesario, en el orden correcto, y sabe quÃ© estÃ¡ actualizado.

---

## ğŸ”„ Â¿QuÃ© se hizo? TransformaciÃ³n de Pipeline Manual â†’ Automatizado

### ANTES (Pipeline Manual):
```
Tu ejecutabas:
1. Rscript script1.R
2. Rscript script2.R
3. Rscript script3.R
...
(tenÃ­as que recordar el orden, rutas, dependencias)
```

### AHORA (Pipeline Snakemake):
```
Ejecutas:
snakemake -j 1

Snakemake:
1. Lee las reglas (quÃ© necesita cada script)
2. Calcula el orden correcto
3. Ejecuta solo lo necesario
4. Verifica que los outputs se generaron
```

---

## ğŸ“ Estructura Creada

### 1. **Snakefile** (Orquestador Principal)
```
Snakefile
â”œâ”€â”€ Carga config/config.yaml
â”œâ”€â”€ Incluye reglas de step1.smk
â”œâ”€â”€ Incluye reglas de step1_5.smk
â””â”€â”€ Define quÃ© se ejecuta por defecto (rule all)
```

**Ejemplo del Snakefile:**
```python
configfile: "config/config.yaml"  # Carga configuraciÃ³n
include: "rules/step1.smk"       # Incluye reglas del Step 1
include: "rules/step1_5.smk"     # Incluye reglas del Step 1.5

rule all:
    input:
        rules.all_step1.output,        # Todos los outputs de Step 1
        rules.all_step1_5.output      # Todos los outputs de Step 1.5
```

---

### 2. **Reglas** (`rules/*.smk`)

Cada regla define **UNA tarea** del pipeline. Por ejemplo:

**Regla para Panel B (Step 1):**
```python
rule panel_b_gt_count_by_position:
    input:
        data = "ruta/al/dato.csv",           # â† Input necesario
        functions = "scripts/utils/functions.R"
    output:
        figure = "outputs/step1/figures/panelB.png",  # â† Output que genera
        table = "outputs/step1/tables/panelB.csv"
    script:
        "scripts/step1/01_panel_b.R"         # â† Script R que ejecuta
```

**Lo que hace Snakemake:**
1. Verifica si existe `outputs/step1/figures/panelB.png`
2. Si NO existe (o si el input cambiÃ³), ejecuta el script R
3. Si SÃ existe y estÃ¡ actualizado, lo omite (no lo vuelve a generar)

---

### 3. **Scripts R Adaptados** (`scripts/step1/*.R`)

**Antes (manual):**
```r
# Rutas hardcodeadas
data <- read.csv("/Users/cesaresparza/.../datos.csv")
output_fig <- "/Users/cesaresparza/.../figura.png"
```

**Ahora (Snakemake):**
```r
# Snakemake pasa las rutas automÃ¡ticamente
input_file <- snakemake@input[["data"]]
output_fig <- snakemake@output[["figure"]]

data <- read.csv(input_file)
# ... anÃ¡lisis ...
ggsave(output_fig, plot, ...)
```

**Ventaja**: Mismo script, pero ahora recibe las rutas automÃ¡ticamente.

---

### 4. **ConfiguraciÃ³n Centralizada** (`config/config.yaml`)

**Antes**: Rutas hardcodeadas en cada script.

**Ahora**: Todo en un solo archivo:
```yaml
paths:
  data:
    processed_clean: "/ruta/a/datos/procesados.csv"
    step1_original: "/ruta/a/datos/originales.csv"
  
analysis:
  vaf_filter_threshold: 0.5
  colors:
    gt: "#D62728"  # Rojo para G>T
```

**Ventaja**: Cambias las rutas una vez, todo el pipeline se actualiza.

---

### 5. **Environment Conda** (`environment.yaml`)

Define todas las dependencias (R, paquetes R, Python, Snakemake):

```yaml
name: als_mirna_pipeline
dependencies:
  - python=3.10
  - snakemake=7.32
  - r-base=4.3.2
  - r-tidyverse
  - r-ggplot2
  ...
```

**Ventaja**: Otro usuario puede recrear el ambiente exacto con:
```bash
conda env create -f environment.yaml
```

---

## ğŸ”„ Flujo de EjecuciÃ³n (Ejemplo: Step 1)

### Cuando ejecutas `snakemake -j 1`:

1. **Snakemake lee `Snakefile`**
   - Carga `config.yaml`
   - Incluye `rules/step1.smk`

2. **Snakemake construye el "grafo de dependencias"**
   ```
   all_step1 necesita:
     â”œâ”€ panelB.png (requiere datos + script panelB.R)
     â”œâ”€ panelC.png (requiere datos + script panelC.R)
     â””â”€ panelD.png (requiere datos + script panelD.R)
     ...
   ```

3. **Snakemake decide quÃ© ejecutar**
   - Si `panelB.png` NO existe â†’ ejecuta `panelB.R`
   - Si `panelB.png` existe pero es mÃ¡s viejo que los inputs â†’ re-ejecuta
   - Si estÃ¡ actualizado â†’ omite (ahorra tiempo)

4. **Snakemake ejecuta en paralelo (si es posible)**
   - `panelB` y `panelC` pueden ejecutarse simultÃ¡neamente (no dependen uno del otro)
   - Pero `panelC` NO puede ejecutarse antes de cargar los datos

5. **Snakemake verifica outputs**
   - Si algÃºn script falla, Snakemake se detiene
   - Si todo funciona, marca `all_step1` como completado

---

## ğŸ“Š Ejemplo Real: Paso 1.5

### Reglas definidas:

**Regla 1: `apply_vaf_filter`**
```python
Input:  step1_original_data.csv
Output: ALL_MUTATIONS_VAF_FILTERED.csv
        vaf_filter_report.csv
        vaf_statistics_by_type.csv
        vaf_statistics_by_mirna.csv
Script: 01_apply_vaf_filter.R
```

**Regla 2: `generate_diagnostic_figures`**
```python
Input:  (depende de Regla 1) â†’ necesita los 4 CSVs de arriba
Output: 11 figuras PNG + 3 tablas CSV
Script: 02_generate_diagnostic_figures.R
```

**Regla 3: `all_step1_5`** (agregador)
```python
Input:  Todas las salidas de Regla 1 + Regla 2
Output: (ninguno nuevo, solo verifica que todo existe)
```

**EjecuciÃ³n:**
```
snakemake -j 1 all_step1_5
  â†“
1. Ejecuta apply_vaf_filter â†’ genera 4 CSVs
  â†“
2. Ejecuta generate_diagnostic_figures â†’ genera 11 PNGs + 3 CSVs
  â†“
3. Verifica que todos los outputs existen â†’ âœ… COMPLETO
```

---

## ğŸ¯ Ventajas del Pipeline Automatizado

1. **Reproducible**: Otro usuario puede ejecutar exactamente lo mismo
2. **Eficiente**: Solo ejecuta lo que falta o cambiÃ³
3. **Orden correcto**: Respeta dependencias automÃ¡ticamente
4. **Configurable**: Rutas y parÃ¡metros en un solo lugar
5. **Escalable**: FÃ¡cil agregar nuevos pasos (solo agregar reglas)

---

## ğŸš€ CÃ³mo se Usa Ahora

```bash
# 1. Crear ambiente (una vez)
conda env create -f environment.yaml
conda activate als_mirna_pipeline

# 2. Configurar rutas (una vez)
# Editar config/config.yaml

# 3. Ejecutar (siempre)
snakemake -j 1              # Todo el pipeline
snakemake -j 1 all_step1    # Solo Step 1
snakemake -n                # Ver quÃ© se ejecutarÃ­a (dry-run)
```

---

## ğŸ“ Resumen de Archivos Creados/Modificados

### Nuevos archivos Snakemake:
- âœ… `Snakefile` - Orquestador principal
- âœ… `rules/step1.smk` - Reglas del Step 1
- âœ… `rules/step1_5.smk` - Reglas del Step 1.5
- âœ… `rules/viewers.smk` - Reglas para generar viewers HTML
- âœ… `config/config.yaml` - ConfiguraciÃ³n centralizada
- âœ… `environment.yaml` - Ambiente conda completo
- âœ… `.gitignore` - Para GitHub
- âœ… `README.md` - Instrucciones de uso

### Scripts R adaptados:
- âœ… `scripts/step1/*.R` - 6 scripts adaptados
- âœ… `scripts/step1_5/*.R` - 2 scripts adaptados
- âœ… `scripts/utils/*.R` - Funciones comunes y builders de viewers

### Estructura de outputs:
- âœ… `outputs/step1/` - Figuras, tablas, logs del Step 1
- âœ… `outputs/step1_5/` - Figuras, tablas, logs del Step 1.5
- âœ… `viewers/` - Viewers HTML generados automÃ¡ticamente

---

## ğŸ“ ConclusiÃ³n

**Lo que tenÃ­as**: Scripts R independientes que ejecutabas manualmente.

**Lo que tienes ahora**: Un pipeline automatizado que:
- Se ejecuta con un comando
- Maneja dependencias automÃ¡ticamente
- Es reproducible y portable
- EstÃ¡ listo para GitHub
- Puede usarse como herramienta por otros usuarios

**Complejidad agregada**: MÃ­nima (solo aprendes la sintaxis de Snakemake)
**Beneficio obtenido**: MÃ¡ximo (automatizaciÃ³n completa)

