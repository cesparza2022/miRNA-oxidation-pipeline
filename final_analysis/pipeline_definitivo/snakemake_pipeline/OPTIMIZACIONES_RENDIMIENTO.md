# üöÄ Optimizaciones de Rendimiento - Pipeline Snakemake

## üîç Problemas Identificados

### 1. **Loop doble anidado ineficiente** (CR√çTICO)
- **Archivo**: `scripts/step1_5/01_apply_vaf_filter.R`
- **L√≠nea 76**: Loop `for (i in 1:nrow())` con loop interno `for (snv_col in snv_cols)`
- **Impacto**: Procesa ~69,000 filas √ó ~400 columnas = **27 millones de iteraciones**
- **Tiempo estimado**: 10-15 minutos

### 2. **Carga repetida de archivos grandes**
- Paneles C y D cargan el mismo archivo raw (278M) por separado
- Cada ejecuci√≥n lee desde disco completo
- **Impacto**: ~30-60 segundos por panel

### 3. **Falta de paralelizaci√≥n**
- Estamos usando `snakemake -j 1` (un solo core)
- Paneles independientes (B, C, D, E, F, G) podr√≠an ejecutarse en paralelo
- **Impacto**: Si tenemos 4 cores, podr√≠amos ser 4x m√°s r√°pidos

---

## üí° Soluciones (Orden de Impacto)

### ‚úÖ SOLUCI√ìN 1: Paralelizaci√≥n (R√ÅPIDA - 0 minutos)
**Impacto**: Reducci√≥n de tiempo en Step 1 de ~6 minutos a ~2 minutos (con 4 cores)

```bash
# En lugar de:
snakemake -j 1

# Usa:
snakemake -j 4  # o m√°s seg√∫n tus cores
```

**Ventajas**:
- Inmediato (solo cambiar comando)
- No requiere cambios en c√≥digo
- Paneles independientes se ejecutan simult√°neamente

---

### ‚ö° SOLUCI√ìN 2: Optimizar Step 1.5 Regla 1 (CR√çTICA - 10 minutos)
**Impacto**: Reducci√≥n de tiempo de ~10-15 min a ~1-2 min (10x m√°s r√°pido)

**Problema**: Loop doble anidado (l√≠nea 76-105)

**Soluci√≥n**: Vectorizar con `dplyr` o `data.table`

**Antes**:
```r
for (i in 1:nrow(data_with_info)) {
  for (snv_col in snv_cols) {
    # calcular VAF y filtrar...
  }
}
```

**Despu√©s** (vectorizado):
```r
# Pivot a formato largo una vez
long_data <- data_with_info %>%
  pivot_longer(...) %>%
  mutate(vaf = snv_count / total_count) %>%
  mutate(snv_count = ifelse(vaf >= 0.5, NA, snv_count)) %>%
  pivot_wider(...)
```

**Tiempo de implementaci√≥n**: ~10 minutos
**Reducci√≥n de tiempo**: 10-15x m√°s r√°pido

---

### üì¶ SOLUCI√ìN 3: Optimizar carga de datos (MEDIA - 5 minutos)
**Impacto**: Reducci√≥n de tiempo de carga de 30-60s a 5-10s

**Cambio**: Reemplazar `read.csv()` por `data.table::fread()`

```r
# Antes:
data <- read.csv(input_file)

# Despu√©s:
library(data.table)
data <- fread(input_file, data.table = FALSE)
```

**Tiempo de implementaci√≥n**: ~5 minutos
**Reducci√≥n**: 5-10x m√°s r√°pido en carga de archivos grandes

---

### üîÑ SOLUCI√ìN 4: Cache de datos procesados (COMPLEJA - 20 minutos)
**Impacto**: Eliminar cargas repetidas del mismo archivo

**Idea**: Procesar raw data una vez, guardar resultado intermedio, reutilizar

**Implementaci√≥n**: Crear regla intermedia que procesa raw data una vez

---

## üéØ Plan de Acci√≥n Recomendado

### Fase 1: Inmediata (5 minutos)
1. ‚úÖ Usar paralelizaci√≥n: `snakemake -j 4`

### Fase 2: Corto plazo (15 minutos)
1. ‚ö° Optimizar Step 1.5 Regla 1 (vectorizar loops)
2. üì¶ Optimizar carga de datos (fread en lugar de read.csv)

### Fase 3: Largo plazo (opcional)
1. üîÑ Implementar cache de datos procesados

---

## üìä Impacto Esperado

**Tiempo actual estimado**:
- Step 1: ~6-8 minutos (sin paralelizaci√≥n)
- Step 1.5 Regla 1: ~10-15 minutos (loop ineficiente)
- Step 1.5 Regla 2: ~2-3 minutos
- **Total**: ~20-26 minutos

**Tiempo despu√©s de optimizaciones**:
- Step 1: ~2 minutos (con -j 4)
- Step 1.5 Regla 1: ~1-2 minutos (vectorizado)
- Step 1.5 Regla 2: ~2-3 minutos
- **Total**: ~5-7 minutos

**Reducci√≥n**: ~75% m√°s r√°pido (4x)

---

## üöÄ ¬øEmpezamos con la paralelizaci√≥n?

La soluci√≥n m√°s r√°pida es simplemente usar m√°s cores. ¬øQuieres que probemos?

```bash
snakemake -j 4 all_step1  # Ejecuta Step 1 con 4 cores en paralelo
```

