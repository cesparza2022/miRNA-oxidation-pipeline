{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Initialize Project Repository and Environment",
        "description": "Set up the project directory structure, initialize version control, and configure R environment with renv for reproducibility.",
        "details": "Create directories: fig/, tables/, runs/, R/. Initialize git. Use renv (>=0.17.3) for dependency management. Add .gitignore and README. Lock package versions in renv.lock. Ensure R >=4.2.0. Prepare config.yaml and data_schema.json templates.",
        "testStrategy": "Verify directory structure, renv lockfile, and initial commit. Confirm R environment can be restored from lockfile.",
        "priority": "high",
        "dependencies": [],
        "status": "in-progress",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Project Directory Structure",
            "description": "Establish the required directories: fig/, tables/, runs/, and R/ within the project root to organize outputs, tables, run logs, and R scripts.",
            "dependencies": [],
            "details": "Use RStudio, OS file explorer, or R's dir.create() to generate the specified folders, ensuring a clear and reproducible structure.",
            "status": "done",
            "testStrategy": "Verify that all specified directories exist and are empty except for placeholder README files if desired."
          },
          {
            "id": 2,
            "title": "Initialize Git Repository and Add Essential Files",
            "description": "Set up git version control in the project root and add a .gitignore file to exclude unnecessary files. Create a README file describing the project.",
            "dependencies": [
              "1.1"
            ],
            "details": "Run git init, create .gitignore with entries for renv/library, .Rhistory, and other transient files. Draft README with project overview and directory descriptions.",
            "status": "done",
            "testStrategy": "Confirm git repository is initialized, .gitignore is present, and README is committed in the initial commit."
          },
          {
            "id": 3,
            "title": "Configure R Environment with renv",
            "description": "Initialize renv (version >=0.17.3) for dependency management and reproducibility, ensuring compatibility with R >=4.2.0.",
            "dependencies": [
              "1.1",
              "1.2"
            ],
            "details": "Run renv::init(), set minimum R version in renv.lock, and install required packages. Lock package versions in renv.lock for reproducibility.",
            "status": "done",
            "testStrategy": "Check that renv.lock is generated and the environment can be restored using renv::restore()."
          },
          {
            "id": 4,
            "title": "Prepare Configuration and Data Schema Templates",
            "description": "Create template files config.yaml and data_schema.json in the project root for future configuration and data validation.",
            "dependencies": [
              "1.1",
              "1.2"
            ],
            "details": "Draft config.yaml with placeholder keys for project settings. Draft data_schema.json with example schema structure for expected data columns and types.",
            "status": "done",
            "testStrategy": "Verify both template files exist, are valid YAML/JSON, and contain placeholder content."
          },
          {
            "id": 5,
            "title": "Verify Environment and Initial Commit",
            "description": "Test the setup by restoring the R environment from renv.lock and confirming all files and directories are tracked in git.",
            "dependencies": [
              "1.3",
              "1.4"
            ],
            "details": "Run renv::restore() to ensure reproducibility. Check git status and log to confirm all essential files are committed.",
            "status": "in-progress",
            "testStrategy": "Successfully restore the environment and confirm the initial commit includes all required files and directories."
          }
        ]
      },
      {
        "id": 2,
        "title": "Migrate and Modularize Existing Notebook Code",
        "description": "Refactor reusable code from the current notebook into R modules with strict APIs and no side effects.",
        "details": "Move robust helpers to R/io.R, R/qc.R, R/normalize.R, R/seedmap.R, R/stats.R, R/cluster.R, R/targets.R, R/plots.R. Add roxygen2 docs. Use stopifnot() for invariants. Remove hidden globals. Export only pure functions.",
        "testStrategy": "Run R CMD check on each module. Confirm all functions are documented and exported. Unit test key helpers.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Identify and Extract Reusable Code from Notebook",
            "description": "Review the existing notebook to locate all robust, reusable helper functions and code segments suitable for modularization.",
            "dependencies": [],
            "details": "Systematically scan the notebook for code that is general-purpose, stateless, and not tightly coupled to notebook-specific logic. Document each candidate function for migration.",
            "status": "pending",
            "testStrategy": "Cross-check extracted functions against notebook usage to ensure all reusable logic is identified."
          },
          {
            "id": 2,
            "title": "Refactor and Organize Code into R Modules",
            "description": "Refactor the extracted code into dedicated R scripts (modules) such as R/io.R, R/qc.R, R/normalize.R, R/seedmap.R, R/stats.R, R/cluster.R, R/targets.R, and R/plots.R, ensuring strict APIs and no side effects.",
            "dependencies": [
              "2.1"
            ],
            "details": "Place each function in the appropriate module based on its functionality. Ensure all functions are pure, parameterized, and do not rely on or modify hidden globals.",
            "status": "pending",
            "testStrategy": "Verify that each module contains only relevant, pure functions and that no side effects or hidden dependencies remain."
          },
          {
            "id": 3,
            "title": "Enforce Invariants and Remove Hidden Globals",
            "description": "Add stopifnot() assertions to enforce input/output invariants and systematically eliminate any hidden global variables from all modules.",
            "dependencies": [
              "2.2"
            ],
            "details": "Review function signatures and bodies to ensure all assumptions are explicit and checked. Refactor code to remove or replace any reliance on global state.",
            "status": "pending",
            "testStrategy": "Run static code analysis and targeted tests to confirm absence of hidden globals and correct enforcement of invariants."
          },
          {
            "id": 4,
            "title": "Document All Functions with roxygen2",
            "description": "Add comprehensive roxygen2 documentation to every exported function, specifying parameters, return values, side effects (if any), and usage examples.",
            "dependencies": [
              "2.3"
            ],
            "details": "Ensure that all documentation is clear, accurate, and sufficient for external users to understand and use the APIs without referencing the original notebook.",
            "status": "pending",
            "testStrategy": "Run roxygen2 to generate documentation and check for completeness and accuracy of all function docs."
          },
          {
            "id": 5,
            "title": "Export and Test Pure Functions",
            "description": "Export only pure, reusable functions from each module and implement unit tests for key helpers to validate correctness and reproducibility.",
            "dependencies": [
              "2.4"
            ],
            "details": "Update NAMESPACE or equivalent to export only intended functions. Write unit tests covering typical and edge cases for each exported function.",
            "status": "pending",
            "testStrategy": "Run R CMD check and all unit tests, confirming that all exported functions are pure, documented, and pass tests without side effects."
          }
        ]
      },
      {
        "id": 3,
        "title": "Implement Data I/O and Schema Parsing",
        "description": "Read input matrix, pair SNV and TOTAL columns, and parse sample metadata from column names.",
        "details": "In R/io.R, use data.table (>=1.14.8) for fast I/O. Pair SNV columns with TOTAL columns using regex. Parse sample names to extract group, timepoint, subject_id, batch. Write tables/sample_metadata.tsv. Support manual overrides.",
        "testStrategy": "Test with example data. Validate correct pairing and metadata extraction. Check output table for completeness.",
        "priority": "high",
        "dependencies": [
          2
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Read Input Matrix Using data.table",
            "description": "Efficiently load the input matrix file using data.table (>=1.14.8) to ensure fast I/O and compatibility with large datasets.",
            "dependencies": [],
            "details": "Implement reading of the input matrix in R/io.R using fread() from data.table. Ensure compatibility with large files and proper handling of delimiters and missing values.",
            "status": "pending",
            "testStrategy": "Test reading speed and correctness with example large and small input matrices. Validate that all rows and columns are loaded as expected."
          },
          {
            "id": 2,
            "title": "Pair SNV and TOTAL Columns Using Regex",
            "description": "Identify and pair SNV columns with their corresponding TOTAL columns using regular expressions to ensure correct mapping for downstream analysis.",
            "dependencies": [
              "3.1"
            ],
            "details": "Develop regex patterns to match SNV and TOTAL column names, ensuring each SNV column is paired with the correct TOTAL column. Handle cases where columns are missing or misnamed.",
            "status": "pending",
            "testStrategy": "Validate correct pairing on test matrices with known column structures. Check for errors or warnings when pairs are missing or ambiguous."
          },
          {
            "id": 3,
            "title": "Parse Sample Metadata from Column Names",
            "description": "Extract group, timepoint, subject_id, and batch information from sample column names using regex and parsing rules.",
            "dependencies": [
              "3.2"
            ],
            "details": "Implement parsing logic in R/io.R to extract metadata fields from column names. Support flexible patterns and edge cases as defined by project requirements.",
            "status": "pending",
            "testStrategy": "Test parsing on a variety of sample name formats, including edge cases. Confirm extracted metadata matches expected values."
          },
          {
            "id": 4,
            "title": "Support Manual Metadata Overrides",
            "description": "Allow users to provide manual overrides for sample metadata to correct or supplement automatic parsing.",
            "dependencies": [
              "3.3"
            ],
            "details": "Implement logic to accept and apply manual metadata overrides, merging them with automatically parsed metadata. Ensure precedence and conflict resolution are handled.",
            "status": "pending",
            "testStrategy": "Test with override files containing corrections and additions. Confirm that overrides are applied correctly and conflicts are resolved as specified."
          },
          {
            "id": 5,
            "title": "Write Sample Metadata Table",
            "description": "Output the parsed and finalized sample metadata to tables/sample_metadata.tsv for downstream use.",
            "dependencies": [
              "3.4"
            ],
            "details": "Write the complete sample metadata table to the specified location in TSV format, ensuring all required fields are present and correctly formatted.",
            "status": "pending",
            "testStrategy": "Verify output file structure, completeness, and correctness. Compare output to expected results for test cases."
          }
        ]
      },
      {
        "id": 4,
        "title": "Implement Data Quality Control and Schema Validation",
        "description": "Check schema, enforce SNV ≤ Total invariant, handle missingness, and summarize coverage.",
        "details": "In R/qc.R, validate all columns per data_schema.json. Use assertthat (>=0.2.1) for checks. Flag samples failing invariants. Summarize coverage and missingness. Write tables/qc_report.tsv.",
        "testStrategy": "Run QC on test data. Confirm all invariants enforced and report generated. Fail if <70% samples pass.",
        "priority": "high",
        "dependencies": [
          3
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Validate Data Columns Against Schema",
            "description": "Check that all columns in the input data conform to the specifications defined in data_schema.json, including data types and required fields.",
            "dependencies": [],
            "details": "Use assertthat (>=0.2.1) to enforce schema constraints for each column as specified in data_schema.json. Ensure all required columns are present and of correct type.",
            "status": "pending",
            "testStrategy": "Run on test data with intentional schema violations to confirm that all mismatches are detected and reported."
          },
          {
            "id": 2,
            "title": "Enforce SNV ≤ Total Invariant",
            "description": "Verify that for each sample, the SNV count does not exceed the corresponding Total count, flagging any violations.",
            "dependencies": [
              "4.1"
            ],
            "details": "Iterate over all paired SNV and Total columns, using assertthat to check SNV ≤ Total for each sample. Record samples failing this invariant.",
            "status": "pending",
            "testStrategy": "Test with data where some SNV values exceed Total to ensure violations are correctly flagged."
          },
          {
            "id": 3,
            "title": "Handle and Summarize Missing Data",
            "description": "Identify missing values in all columns, quantify missingness per sample and per column, and prepare this information for reporting.",
            "dependencies": [
              "4.1"
            ],
            "details": "Scan the dataset for NA or missing values, compute missingness rates, and structure results for inclusion in the QC report.",
            "status": "pending",
            "testStrategy": "Use datasets with known missing patterns to verify accurate detection and quantification."
          },
          {
            "id": 4,
            "title": "Summarize Coverage Metrics",
            "description": "Calculate and summarize coverage statistics (e.g., mean, median, min, max) for relevant columns across all samples.",
            "dependencies": [
              "4.1"
            ],
            "details": "Aggregate coverage-related columns and compute summary statistics for each sample and globally.",
            "status": "pending",
            "testStrategy": "Check that summary statistics match manual calculations on test datasets."
          },
          {
            "id": 5,
            "title": "Generate and Write QC Report",
            "description": "Compile schema validation results, invariant violations, missingness, and coverage summaries into a comprehensive QC report and write to tables/qc_report.tsv.",
            "dependencies": [
              "4.2",
              "4.3",
              "4.4"
            ],
            "details": "Integrate all QC outputs into a single tabular report, ensuring clear labeling of failed samples and summary metrics.",
            "status": "pending",
            "testStrategy": "Verify that the report contains all required sections and accurately reflects the results of previous subtasks."
          }
        ]
      },
      {
        "id": 5,
        "title": "Normalize Data and Compute VAF/RPM",
        "description": "Calculate per-sample library size, SNV-RPM, and VAF as primary endpoint.",
        "details": "In R/normalize.R, compute R_p = sum(Total_miRNA) per sample. Calculate SNV-RPM and VAF = SNV_count / Total_miRNA. Output tables/libsize.tsv, tables/snv_rpm_long.tsv, tables/position_map.tsv.",
        "testStrategy": "Cross-check computed values with manual calculations. Validate output tables for all samples.",
        "priority": "high",
        "dependencies": [
          4
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Aggregate Total miRNA Counts Per Sample",
            "description": "Sum the total miRNA counts for each sample to compute the per-sample library size (R_p).",
            "dependencies": [],
            "details": "In R/normalize.R, implement logic to sum Total_miRNA for each sample and output the results to tables/libsize.tsv.",
            "status": "pending",
            "testStrategy": "Cross-check computed library sizes with manual calculations for a subset of samples."
          },
          {
            "id": 2,
            "title": "Calculate SNV Counts and Normalize to RPM",
            "description": "For each sample and SNV, calculate the SNV read count and normalize it to Reads Per Million (SNV-RPM) using the sample's library size.",
            "dependencies": [
              "5.1"
            ],
            "details": "In R/normalize.R, compute SNV-RPM as (SNV_count / R_p) * 1,000,000 for each SNV in each sample. Output to tables/snv_rpm_long.tsv.",
            "status": "pending",
            "testStrategy": "Validate SNV-RPM values by comparing with manual calculations and ensure correct normalization."
          },
          {
            "id": 3,
            "title": "Compute Variant Allele Frequency (VAF)",
            "description": "Calculate VAF for each SNV in each sample as the ratio of SNV_count to Total_miRNA.",
            "dependencies": [
              "5.1"
            ],
            "details": "In R/normalize.R, implement VAF = SNV_count / Total_miRNA for each SNV per sample. Store results for downstream analysis.",
            "status": "pending",
            "testStrategy": "Check VAF calculations against expected values for selected SNVs and samples."
          },
          {
            "id": 4,
            "title": "Generate Output Tables for Normalized Data",
            "description": "Format and write the computed library sizes, SNV-RPM, and VAF values to the required output files.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3"
            ],
            "details": "Ensure tables/libsize.tsv, tables/snv_rpm_long.tsv, and tables/position_map.tsv are generated with correct structure and content.",
            "status": "pending",
            "testStrategy": "Verify output tables for completeness, correct formatting, and consistency with input data."
          },
          {
            "id": 5,
            "title": "Validate and Document Normalization Workflow",
            "description": "Cross-check all computed values, validate output tables, and document the normalization and calculation procedures.",
            "dependencies": [
              "5.4"
            ],
            "details": "Perform manual validation of a subset of results, ensure reproducibility, and update documentation to describe normalization logic and output formats.",
            "status": "pending",
            "testStrategy": "Confirm all outputs match manual calculations and that documentation is clear and complete."
          }
        ]
      },
      {
        "id": 6,
        "title": "Parse and Annotate Seed Positions",
        "description": "Parse pos:mut to integer position and mutation, and mark seed positions (2–8).",
        "details": "In R/seedmap.R, use stringr (>=1.5.0) to parse pos:mut. Annotate each row with is_seed (TRUE if 2≤pos≤8). Add mark_seed() helper.",
        "testStrategy": "Unit test parsing logic. Confirm correct seed annotation on test cases.",
        "priority": "medium",
        "dependencies": [
          5
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Extract Position and Mutation from pos:mut String",
            "description": "Parse each pos:mut string to separate the integer position and the mutation using stringr functions.",
            "dependencies": [],
            "details": "Use stringr (>=1.5.0) functions such as str_split or str_extract to split the pos:mut string into its numeric position and mutation components.",
            "status": "pending",
            "testStrategy": "Unit test with a variety of pos:mut formats to ensure correct extraction of position and mutation."
          },
          {
            "id": 2,
            "title": "Convert Extracted Position to Integer",
            "description": "Ensure the extracted position is converted to an integer type for downstream processing.",
            "dependencies": [
              "6.1"
            ],
            "details": "Apply as.integer or equivalent conversion to the parsed position value.",
            "status": "pending",
            "testStrategy": "Test with valid and invalid position strings to confirm correct integer conversion and error handling."
          },
          {
            "id": 3,
            "title": "Annotate Seed Positions",
            "description": "Add a logical column is_seed indicating TRUE if 2 ≤ position ≤ 8, otherwise FALSE.",
            "dependencies": [
              "6.2"
            ],
            "details": "Create a new column is_seed in the data frame, using vectorized logical comparison.",
            "status": "pending",
            "testStrategy": "Test annotation on edge cases (positions 1, 2, 8, 9) to confirm correct TRUE/FALSE assignment."
          },
          {
            "id": 4,
            "title": "Implement mark_seed() Helper Function",
            "description": "Develop a reusable helper function mark_seed() that takes a data frame and adds the is_seed annotation.",
            "dependencies": [
              "6.3"
            ],
            "details": "Define mark_seed() in R/seedmap.R to encapsulate the seed annotation logic for reuse.",
            "status": "pending",
            "testStrategy": "Unit test mark_seed() on sample data frames to ensure correct output and no side effects."
          },
          {
            "id": 5,
            "title": "Integrate and Document Parsing and Annotation Workflow",
            "description": "Integrate the parsing and annotation steps into the main workflow and provide inline documentation.",
            "dependencies": [
              "6.4"
            ],
            "details": "Update R/seedmap.R to call the parsing and mark_seed() logic, and add comments explaining each step.",
            "status": "pending",
            "testStrategy": "Review code for clarity, run end-to-end tests on representative input, and verify documentation completeness."
          }
        ]
      },
      {
        "id": 7,
        "title": "Summarize miRNA Expression and Select Top miRNAs",
        "description": "Aggregate per-miRNA totals, define expression floor, and select top miRNAs for downstream analysis.",
        "details": "In R/normalize.R, compute total expression per miRNA per sample. Implement grid-sweep of expression floors (default 25th percentile). Output tables/expr_summary.tsv, tables/top_miRNAs.tsv, fig/top_miRNAs_bar.png.",
        "testStrategy": "Check that selected miRNAs match expected percentiles. Visualize and verify barplot.",
        "priority": "medium",
        "dependencies": [
          5
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Aggregate Total miRNA Expression per Sample",
            "description": "Compute the total expression value for each miRNA across all samples using the normalized expression matrix.",
            "dependencies": [],
            "details": "Implement code in R/normalize.R to sum expression counts for each miRNA per sample, ensuring accurate aggregation for downstream filtering.",
            "status": "pending",
            "testStrategy": "Verify that the output matches manual aggregation for a subset of miRNAs and samples."
          },
          {
            "id": 2,
            "title": "Generate Per-miRNA Expression Summary Table",
            "description": "Create a summary table (expr_summary.tsv) containing total and per-sample expression statistics for each miRNA.",
            "dependencies": [
              "7.1"
            ],
            "details": "Output a TSV file with columns for miRNA ID, total expression, mean, median, and other relevant statistics.",
            "status": "pending",
            "testStrategy": "Check that summary statistics are correctly calculated and that the table structure matches specification."
          },
          {
            "id": 3,
            "title": "Implement Grid-Sweep of Expression Floors",
            "description": "Systematically apply a range of expression floor thresholds (including the default 25th percentile) to filter lowly expressed miRNAs.",
            "dependencies": [
              "7.2"
            ],
            "details": "In R/normalize.R, implement logic to sweep through multiple floor values and record the number of miRNAs retained at each threshold.",
            "status": "pending",
            "testStrategy": "Confirm that the grid-sweep correctly filters miRNAs and that the default threshold matches the 25th percentile."
          },
          {
            "id": 4,
            "title": "Select Top miRNAs for Downstream Analysis",
            "description": "Based on the chosen expression floor, select the top-expressed miRNAs and output their identifiers and statistics to top_miRNAs.tsv.",
            "dependencies": [
              "7.3"
            ],
            "details": "Rank miRNAs by total expression, apply the selected floor, and write the resulting list to a TSV file for downstream use.",
            "status": "pending",
            "testStrategy": "Ensure that the selected miRNAs correspond to the expected top percentile and that the output file is correctly formatted."
          },
          {
            "id": 5,
            "title": "Visualize Top miRNAs with Barplot",
            "description": "Generate a barplot (fig/top_miRNAs_bar.png) visualizing the expression levels of the selected top miRNAs.",
            "dependencies": [
              "7.4"
            ],
            "details": "Use R plotting libraries to create a clear barplot of top miRNA expression, labeling axes and miRNA IDs appropriately.",
            "status": "pending",
            "testStrategy": "Visually inspect the barplot for accuracy and clarity; confirm that it matches the data in top_miRNAs.tsv."
          }
        ]
      },
      {
        "id": 8,
        "title": "Validate Sample Metadata and Cohort Parsing",
        "description": "Ensure correct parsing of cohorts, timepoints, and other metadata from sample names.",
        "details": "In R/io.R, apply regex rules and manual overrides. Flag if >2% samples are ambiguous. Output tables/sample_metadata.tsv.",
        "testStrategy": "Test with edge-case sample names. Confirm correct mapping and flagging.",
        "priority": "medium",
        "dependencies": [
          3
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define and Document Metadata Parsing Rules",
            "description": "Specify regex patterns and manual override logic for extracting cohorts, timepoints, and other metadata from sample names. Ensure rules cover expected sample ID formats and edge cases.",
            "dependencies": [],
            "details": "Review sample naming conventions and document all parsing rules in R/io.R. Include examples and rationale for each rule.",
            "status": "pending",
            "testStrategy": "Validate rules against a representative set of sample names, including edge cases, and confirm correct extraction of all metadata fields."
          },
          {
            "id": 2,
            "title": "Implement Automated Metadata Extraction",
            "description": "Develop R code in io.R to apply regex rules and manual overrides for parsing sample metadata. Ensure extraction of cohort, timepoint, subject_id, and batch information.",
            "dependencies": [
              "8.1"
            ],
            "details": "Code functions to parse sample names and extract metadata fields. Integrate manual override capability for exceptions.",
            "status": "pending",
            "testStrategy": "Run automated extraction on full dataset and verify output against expected results for a subset of samples."
          },
          {
            "id": 3,
            "title": "Flag Ambiguous Sample Metadata",
            "description": "Detect and flag samples where metadata parsing is ambiguous or incomplete. Trigger a warning if more than 2% of samples are ambiguous.",
            "dependencies": [
              "8.2"
            ],
            "details": "Implement logic to identify ambiguous parsing results and calculate the percentage of affected samples. Set up warning system for threshold breaches.",
            "status": "pending",
            "testStrategy": "Test with datasets containing known ambiguous samples and confirm correct flagging and warning behavior."
          },
          {
            "id": 4,
            "title": "Generate and Validate Sample Metadata Table",
            "description": "Output parsed metadata to tables/sample_metadata.tsv. Ensure table includes all required fields and matches schema specifications.",
            "dependencies": [
              "8.2",
              "8.3"
            ],
            "details": "Write R code to format and export metadata as TSV. Validate against data_schema.json and check for completeness.",
            "status": "pending",
            "testStrategy": "Compare output table to schema requirements and manually inspect a random sample for accuracy."
          },
          {
            "id": 5,
            "title": "Perform Quality Control and Consistency Checks",
            "description": "Assess metadata quality by checking for standardization, parseability, and consistency across samples. Document anomalies and suggest improvements.",
            "dependencies": [
              "8.4"
            ],
            "details": "Review metadata for use of controlled terms, consistent formats, and logical relationships. Summarize findings and recommend corrective actions if needed.",
            "status": "pending",
            "testStrategy": "Apply automated and manual checks to the final metadata table. Report any inconsistencies or deviations from standards."
          }
        ]
      },
      {
        "id": 9,
        "title": "Global G>T Signal Analysis (ALS vs Control)",
        "description": "Quantify aggregate G>T levels in ALS vs Control using GLM/GLMM and stratified permutation.",
        "details": "In R/stats.R, use lme4 (>=1.1-34) for GLMM (fixed: group; random: subject/miRNA). Permute labels within batch/time strata. Output tables/global_gt_tests.tsv, fig/gt_violin_by_group.png.",
        "testStrategy": "Validate model fit and permutation p-values. Confirm violin plot matches summary stats.",
        "priority": "high",
        "dependencies": [
          7,
          8
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Prepare and Aggregate G>T Signal Data",
            "description": "Aggregate G>T mutation counts per sample and group, ensuring data includes relevant covariates (group, subject, miRNA, batch, time).",
            "dependencies": [],
            "details": "Extract and preprocess raw mutation data to compute aggregate G>T levels for each sample, annotating with group (ALS or Control), subject, miRNA, batch, and time information.",
            "status": "pending",
            "testStrategy": "Verify that aggregated data matches expected totals and includes all required annotation fields."
          },
          {
            "id": 2,
            "title": "Fit GLM and GLMM Models for Group Comparison",
            "description": "Use lme4 (>=1.1-34) in R to fit GLM and GLMM models comparing G>T levels between ALS and Control, with group as fixed effect and subject/miRNA as random effects.",
            "dependencies": [
              "9.1"
            ],
            "details": "Implement model fitting in R/stats.R using glmer() for GLMM (formula: G>T ~ group + (1|subject) + (1|miRNA)), and glm() for GLM as appropriate.",
            "status": "pending",
            "testStrategy": "Check model convergence, inspect fixed and random effect estimates, and confirm model fit diagnostics."
          },
          {
            "id": 3,
            "title": "Perform Stratified Permutation Testing",
            "description": "Permute group labels within batch and time strata to generate null distributions and compute permutation p-values for group effect.",
            "dependencies": [
              "9.2"
            ],
            "details": "Implement stratified permutation in R, ensuring labels are only shuffled within batch/time strata, and rerun GLMM for each permutation to build empirical p-value distribution.",
            "status": "pending",
            "testStrategy": "Validate that permutations are correctly stratified and that permutation p-values are consistent with model-based p-values."
          },
          {
            "id": 4,
            "title": "Generate Output Tables and Statistical Summaries",
            "description": "Summarize model results and permutation test statistics in tables/global_gt_tests.tsv, including effect sizes, confidence intervals, and p-values.",
            "dependencies": [
              "9.3"
            ],
            "details": "Format and export statistical results to the specified TSV file, ensuring all relevant metrics are included and clearly labeled.",
            "status": "pending",
            "testStrategy": "Confirm that output table matches model results and includes all required statistics."
          },
          {
            "id": 5,
            "title": "Visualize G>T Signal by Group",
            "description": "Create violin plot of G>T levels by group (ALS vs Control) and save as fig/gt_violin_by_group.png.",
            "dependencies": [
              "9.4"
            ],
            "details": "Use ggplot2 or similar in R to generate a violin plot, overlaying summary statistics as needed, and ensure plot aesthetics match project standards.",
            "status": "pending",
            "testStrategy": "Verify that the violin plot accurately reflects the underlying data and matches summary statistics in the output table."
          }
        ]
      },
      {
        "id": 10,
        "title": "Base Change Composition Analysis",
        "description": "Compare G>T to other base changes (G>A, G>C) by group using multinomial/Dirichlet-multinomial models.",
        "details": "In R/stats.R, use DirichletMultinomial (>=1.40.0) for composition analysis. Output tables/composition_by_group.tsv, fig/composition_G_changes.png.",
        "testStrategy": "Check model fit and confidence intervals. Visualize composition bars.",
        "priority": "medium",
        "dependencies": [
          5,
          8
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Prepare Base Change Count Data by Group",
            "description": "Aggregate counts of G>T, G>A, and G>C base changes for each group, ensuring data is formatted for multinomial/Dirichlet-multinomial modeling.",
            "dependencies": [],
            "details": "Extract and tabulate mutation counts from input data, grouping by relevant sample or experimental group. Format as a matrix or table suitable for DirichletMultinomial input.",
            "status": "pending",
            "testStrategy": "Verify that counts for each mutation type and group sum correctly and match raw data."
          },
          {
            "id": 2,
            "title": "Fit Dirichlet-Multinomial Models to Base Change Data",
            "description": "Apply the DirichletMultinomial package (>=1.40.0) in R to model the composition of G>T, G>A, and G>C changes by group.",
            "dependencies": [
              "10.1"
            ],
            "details": "Use DirichletMultinomial::dmn() or equivalent to fit models for each group. Select model parameters and assess fit as per package documentation.",
            "status": "pending",
            "testStrategy": "Check model convergence, inspect parameter estimates, and confirm model fit diagnostics."
          },
          {
            "id": 3,
            "title": "Compare Base Change Compositions Across Groups",
            "description": "Statistically compare the proportions of G>T, G>A, and G>C changes between groups using the fitted models.",
            "dependencies": [
              "10.2"
            ],
            "details": "Perform hypothesis testing or calculate confidence intervals for differences in base change composition between groups, leveraging model outputs.",
            "status": "pending",
            "testStrategy": "Ensure statistical tests are appropriate for multinomial/Dirichlet-multinomial models and results are reproducible."
          },
          {
            "id": 4,
            "title": "Generate Output Table of Compositions by Group",
            "description": "Summarize and export the estimated base change compositions and relevant statistics to tables/composition_by_group.tsv.",
            "dependencies": [
              "10.3"
            ],
            "details": "Format results as a TSV file with group, mutation type, estimated proportion, and confidence intervals.",
            "status": "pending",
            "testStrategy": "Validate table structure, check for completeness, and confirm values match model outputs."
          },
          {
            "id": 5,
            "title": "Visualize G>T Composition Changes by Group",
            "description": "Create and export a bar plot or similar visualization of G>T (and optionally G>A, G>C) composition by group to fig/composition_G_changes.png.",
            "dependencies": [
              "10.4"
            ],
            "details": "Use R plotting libraries to visualize the estimated compositions, highlighting group differences and including error bars as appropriate.",
            "status": "pending",
            "testStrategy": "Confirm plot matches table data, axes are labeled, and figure aesthetics meet project standards."
          }
        ]
      },
      {
        "id": 11,
        "title": "Positional Mutation Summaries",
        "description": "Summarize and rank positions by G>T VAF and RPM, both overall and within seed region.",
        "details": "In R/stats.R, aggregate VAF/RPM per position. Bootstrap CIs with boot (>=1.3-28). Output tables/position_overall_rank.tsv, tables/seed_position_rank.tsv, figs/position_barplot_overall.png, figs/seed_position_barplot.png.",
        "testStrategy": "Check rankings and CIs. Confirm plots shade seed region correctly.",
        "priority": "medium",
        "dependencies": [
          6,
          9
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Aggregate G>T VAF and RPM Per Position",
            "description": "Compute and aggregate the variant allele frequency (VAF) and reads per million (RPM) for G>T mutations at each genomic position using available data.",
            "dependencies": [],
            "details": "Implement aggregation logic in R/stats.R to calculate VAF and RPM for each position across all samples.",
            "status": "pending",
            "testStrategy": "Verify that aggregated values match expected results for a test dataset."
          },
          {
            "id": 2,
            "title": "Summarize and Rank Positions Overall",
            "description": "Summarize all positions by their G>T VAF and RPM, and rank them accordingly for the entire region.",
            "dependencies": [
              "11.1"
            ],
            "details": "Generate a ranked summary table (tables/position_overall_rank.tsv) based on aggregated metrics.",
            "status": "pending",
            "testStrategy": "Check that the ranking order is correct and matches manual calculations."
          },
          {
            "id": 3,
            "title": "Summarize and Rank Positions Within Seed Region",
            "description": "Subset positions within the defined seed region, summarize their G>T VAF and RPM, and rank them.",
            "dependencies": [
              "11.1"
            ],
            "details": "Produce a ranked summary table (tables/seed_position_rank.tsv) for seed region positions only.",
            "status": "pending",
            "testStrategy": "Confirm that only seed region positions are included and rankings are accurate."
          },
          {
            "id": 4,
            "title": "Bootstrap Confidence Intervals for VAF and RPM",
            "description": "Apply bootstrapping (using the boot package, version >=1.3-28) to estimate confidence intervals for VAF and RPM at each position, both overall and within the seed region.",
            "dependencies": [
              "11.2",
              "11.3"
            ],
            "details": "Integrate bootstrapping into the R workflow and append CIs to the output tables.",
            "status": "pending",
            "testStrategy": "Validate that CIs are present, correctly calculated, and reproducible for a fixed seed."
          },
          {
            "id": 5,
            "title": "Generate Barplots for Overall and Seed Region Rankings",
            "description": "Create barplots visualizing the ranked positions by G>T VAF and RPM, shading the seed region appropriately.",
            "dependencies": [
              "11.2",
              "11.3",
              "11.4"
            ],
            "details": "Output figures as figs/position_barplot_overall.png and figs/seed_position_barplot.png, ensuring correct seed region shading.",
            "status": "pending",
            "testStrategy": "Check that plots display correct rankings, CIs, and seed region shading as specified."
          }
        ]
      },
      {
        "id": 12,
        "title": "Mutation Type Mixture at Top Positions",
        "description": "For top positions, summarize mixture of G>T/G>A/G>C mutations.",
        "details": "In R/stats.R, identify top positions, compute mutation type fractions, and plot stacked bars. Output tables/toppos_mutation_mix.tsv, fig/toppos_mut_mix.png.",
        "testStrategy": "Check mixture fractions and plot accuracy.",
        "priority": "medium",
        "dependencies": [
          11
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Identify Top Mutated Positions",
            "description": "Determine the genomic positions with the highest mutation rates based on existing mutation data.",
            "dependencies": [],
            "details": "Use R/stats.R to aggregate mutation counts or rates per position and select the top positions for further analysis.",
            "status": "pending",
            "testStrategy": "Verify that the selected top positions match expected rankings from input data."
          },
          {
            "id": 2,
            "title": "Extract and Classify Mutation Types at Top Positions",
            "description": "For each top position, extract mutation events and classify them as G>T, G>A, or G>C.",
            "dependencies": [
              "12.1"
            ],
            "details": "Parse mutation data for the top positions and categorize each mutation event by type.",
            "status": "pending",
            "testStrategy": "Check that all mutation events at top positions are correctly classified into the three specified types."
          },
          {
            "id": 3,
            "title": "Compute Mutation Type Fractions per Position",
            "description": "Calculate the fraction of each mutation type (G>T, G>A, G>C) at every top position.",
            "dependencies": [
              "12.2"
            ],
            "details": "For each top position, compute the proportion of each mutation type relative to the total mutations at that position.",
            "status": "pending",
            "testStrategy": "Confirm that fractions sum to 1 for each position and match manual calculations for sample positions."
          },
          {
            "id": 4,
            "title": "Generate Output Table of Mutation Mixtures",
            "description": "Create a tab-separated table summarizing the mutation type fractions for each top position.",
            "dependencies": [
              "12.3"
            ],
            "details": "Output the results as tables/toppos_mutation_mix.tsv with columns for position and fractions of G>T, G>A, and G>C.",
            "status": "pending",
            "testStrategy": "Validate table format, column names, and data consistency with computed fractions."
          },
          {
            "id": 5,
            "title": "Plot Stacked Bar Chart of Mutation Type Mixtures",
            "description": "Visualize the mutation type fractions at top positions using a stacked bar plot.",
            "dependencies": [
              "12.4"
            ],
            "details": "Use R plotting functions to generate fig/toppos_mut_mix.png, showing each position as a stacked bar of mutation type fractions.",
            "status": "pending",
            "testStrategy": "Check that the plot accurately reflects the table data and mutation type proportions are visually correct."
          }
        ]
      },
      {
        "id": 13,
        "title": "Differential Mutation Testing by Position (ALS vs Control)",
        "description": "Test for differential mutation rates per position using GLMM and permutation, with BH-FDR correction.",
        "details": "In R/stats.R, fit GLMM per position, adjust p-values with p.adjust(method='BH'). Output tables/position_tests.tsv, fig/volcano_position_effects.png.",
        "testStrategy": "Validate FDR correction and volcano plot. Confirm significant positions flagged.",
        "priority": "high",
        "dependencies": [
          11
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Prepare Input Data for Per-Position Mutation Analysis",
            "description": "Aggregate and format mutation count and sample metadata to enable per-position comparison between ALS and control groups.",
            "dependencies": [],
            "details": "Ensure input matrices are structured so that each genomic position has associated mutation counts and relevant sample group labels (ALS or control).",
            "status": "pending",
            "testStrategy": "Verify that all positions and samples are represented and group labels are correct."
          },
          {
            "id": 2,
            "title": "Fit GLMM for Each Genomic Position",
            "description": "For each position, fit a generalized linear mixed model (GLMM) to test for differential mutation rates between ALS and control groups.",
            "dependencies": [
              "13.1"
            ],
            "details": "Implement per-position GLMMs in R/stats.R, specifying group as a fixed effect and including random effects as appropriate.",
            "status": "pending",
            "testStrategy": "Check model convergence and confirm that model outputs are generated for all positions."
          },
          {
            "id": 3,
            "title": "Perform Permutation Testing for Significance Assessment",
            "description": "Conduct permutation tests to empirically assess the significance of group effects at each position.",
            "dependencies": [
              "13.2"
            ],
            "details": "Randomly permute group labels and refit GLMMs to generate null distributions of test statistics for each position.",
            "status": "pending",
            "testStrategy": "Validate that permutation p-values are computed and that the null distribution is well-behaved."
          },
          {
            "id": 4,
            "title": "Adjust P-values for Multiple Testing Using BH-FDR",
            "description": "Apply Benjamini-Hochberg FDR correction to the set of p-values obtained from GLMM and permutation tests.",
            "dependencies": [
              "13.3"
            ],
            "details": "Use p.adjust(method='BH') in R to adjust raw p-values for all tested positions.",
            "status": "pending",
            "testStrategy": "Confirm that adjusted p-values are present and that significant positions are correctly flagged."
          },
          {
            "id": 5,
            "title": "Generate Output Tables and Volcano Plot",
            "description": "Output results as tables and visualize differential effects using a volcano plot.",
            "dependencies": [
              "13.4"
            ],
            "details": "Write tables/position_tests.tsv with test statistics and adjusted p-values; create fig/volcano_position_effects.png highlighting significant positions.",
            "status": "pending",
            "testStrategy": "Check that output files are correctly formatted and that the volcano plot accurately reflects statistical results."
          }
        ]
      },
      {
        "id": 14,
        "title": "Seed vs Non-Seed Enrichment Analysis",
        "description": "Quantify enrichment of mutations in seed vs non-seed regions using binomial/permutation tests.",
        "details": "In R/stats.R, compute odds ratios, CIs, and p/q values. Output tables/seed_nonseed_enrichment.tsv, fig/seed_vs_nonseed_odds.png.",
        "testStrategy": "Check enrichment statistics and plot clarity.",
        "priority": "medium",
        "dependencies": [
          13
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Seed and Non-Seed Regions and Annotate Mutations",
            "description": "Clearly define the criteria for seed and non-seed regions and annotate all mutations in the dataset accordingly.",
            "dependencies": [],
            "details": "Establish operational definitions for seed and non-seed regions based on biological or sequence criteria. Annotate each mutation in the input data as belonging to either a seed or non-seed region.",
            "status": "pending",
            "testStrategy": "Verify that all mutations are correctly labeled as seed or non-seed and that definitions are consistent with project standards."
          },
          {
            "id": 2,
            "title": "Tabulate Mutation Counts for Seed and Non-Seed Regions",
            "description": "Count the number of mutations and background sites in seed and non-seed regions to prepare contingency tables for statistical analysis.",
            "dependencies": [
              "14.1"
            ],
            "details": "Generate a table summarizing the number of mutated and non-mutated sites in seed and non-seed regions. Ensure counts are accurate and match the annotated data.",
            "status": "pending",
            "testStrategy": "Cross-check counts with raw data and confirm that totals match expected values for both regions."
          },
          {
            "id": 3,
            "title": "Perform Enrichment Analysis Using Binomial and Permutation Tests",
            "description": "Apply binomial and permutation tests to assess enrichment of mutations in seed versus non-seed regions.",
            "dependencies": [
              "14.2"
            ],
            "details": "Implement statistical tests in R (stats.R) to compare observed mutation frequencies in seed and non-seed regions against expected distributions. Use both binomial and permutation approaches for robustness.",
            "status": "pending",
            "testStrategy": "Validate test implementation with simulated data and confirm that p-values behave as expected under null and alternative scenarios."
          },
          {
            "id": 4,
            "title": "Compute Odds Ratios, Confidence Intervals, and Adjusted p/q-values",
            "description": "Calculate odds ratios, 95% confidence intervals, and adjust p-values for multiple testing to obtain q-values.",
            "dependencies": [
              "14.3"
            ],
            "details": "Use R to compute odds ratios and confidence intervals from contingency tables. Apply appropriate multiple testing correction (e.g., Benjamini-Hochberg) to derive q-values.",
            "status": "pending",
            "testStrategy": "Check that statistical outputs are correctly calculated and formatted, and that q-values are consistent with p-value adjustment methods."
          },
          {
            "id": 5,
            "title": "Generate Output Tables and Visualization",
            "description": "Output results to tables/seed_nonseed_enrichment.tsv and create a figure fig/seed_vs_nonseed_odds.png summarizing the enrichment analysis.",
            "dependencies": [
              "14.4"
            ],
            "details": "Format and export all statistical results to the specified TSV file. Create a clear and informative plot (e.g., forest plot or bar plot) visualizing odds ratios and confidence intervals for seed vs non-seed enrichment.",
            "status": "pending",
            "testStrategy": "Confirm that output files are correctly generated, tables are complete, and the figure accurately represents the statistical findings with clear labeling."
          }
        ]
      },
      {
        "id": 15,
        "title": "Position-Specific G>T Difference Curves",
        "description": "Plot ΔVAF (ALS–Control) per position with CIs, seed shading, and significance stars.",
        "details": "In R/plots.R, implement plot_gt_position_by_group(). Use ggplot2 (>=3.4.0). Output tables/position_delta.tsv, fig/position_delta_curve.png.",
        "testStrategy": "Confirm plot aesthetics: seed shaded, stars for q<0.05, correct ΔVAF values.",
        "priority": "medium",
        "dependencies": [
          13
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Load and Prepare Position-Specific ΔVAF Data",
            "description": "Read in the per-position ΔVAF (ALS–Control) data, confidence intervals, seed region annotation, and significance results from the appropriate source files (e.g., tables/position_delta.tsv). Ensure data is formatted for plotting.",
            "dependencies": [],
            "details": "Implement data loading and preprocessing in R, handling missing values and ensuring all required columns (position, ΔVAF, CI bounds, seed flag, q-value) are present.",
            "status": "pending",
            "testStrategy": "Verify that the loaded data matches expected structure and values, and that all required columns are present for plotting."
          },
          {
            "id": 2,
            "title": "Plot ΔVAF per Position with Confidence Intervals",
            "description": "Create a ggplot2 line plot of ΔVAF by position, adding ribbons or error bars to represent confidence intervals for each position.",
            "dependencies": [
              "15.1"
            ],
            "details": "Use ggplot2 (>=3.4.0) to plot ΔVAF (y-axis) against position (x-axis), overlaying confidence intervals using geom_ribbon or geom_errorbar as appropriate.",
            "status": "pending",
            "testStrategy": "Check that the plot displays ΔVAF and CIs correctly for all positions, matching the data."
          },
          {
            "id": 3,
            "title": "Shade Seed Region on Plot",
            "description": "Highlight the seed region on the plot by adding a shaded background or overlay to distinguish it from non-seed positions.",
            "dependencies": [
              "15.2"
            ],
            "details": "Use ggplot2's annotate or geom_rect to shade the seed region, based on the seed flag or position range in the data.",
            "status": "pending",
            "testStrategy": "Confirm that the seed region is shaded accurately and matches the defined seed positions."
          },
          {
            "id": 4,
            "title": "Annotate Significance Stars for Positions",
            "description": "Add significance stars to positions where the q-value is below the 0.05 threshold, indicating statistically significant ΔVAF differences.",
            "dependencies": [
              "15.2"
            ],
            "details": "Use ggplot2's geom_text or annotate to place stars above or on the relevant positions, based on q-value criteria.",
            "status": "pending",
            "testStrategy": "Verify that stars appear only at positions with q < 0.05 and are clearly visible on the plot."
          },
          {
            "id": 5,
            "title": "Export Final Plot and Data Table",
            "description": "Save the completed plot as fig/position_delta_curve.png and export the processed data as tables/position_delta.tsv.",
            "dependencies": [
              "15.3",
              "15.4"
            ],
            "details": "Use ggsave for the plot and write.table or similar for the data, ensuring output matches required formats and locations.",
            "status": "pending",
            "testStrategy": "Check that the output files are generated, correctly named, and contain the expected content and formatting."
          }
        ]
      },
      {
        "id": 16,
        "title": "Per-miRNA Positionwise Testing and Heatmaps",
        "description": "For each top miRNA, test positionwise mutation rates and visualize as heatmaps.",
        "details": "In R/stats.R, run BH-FDR across miRNA×position. In R/plots.R, plot heatmaps with pheatmap (>=1.0.12). Output tables/miRNA_position_tests.tsv, fig/seed_heatmap_by_miRNA.png.",
        "testStrategy": "Check FDR correction and heatmap accuracy.",
        "priority": "medium",
        "dependencies": [
          7,
          13
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Aggregate Per-miRNA Positionwise Mutation Data",
            "description": "Collect and organize mutation rate data for each position within each top miRNA, ensuring data is structured for downstream statistical testing.",
            "dependencies": [],
            "details": "Extract mutation counts or rates for all positions of each selected miRNA from the relevant datasets, preparing a matrix with miRNAs as rows and positions as columns.",
            "status": "pending",
            "testStrategy": "Verify completeness and correctness of aggregated data by cross-checking with raw input and summary statistics."
          },
          {
            "id": 2,
            "title": "Perform Positionwise Statistical Testing Across miRNAs",
            "description": "For each miRNA and position, conduct statistical tests to assess mutation rate significance, accounting for multiple testing.",
            "dependencies": [
              "16.1"
            ],
            "details": "Apply appropriate statistical tests (e.g., binomial or Poisson) to each miRNA-position pair to determine if mutation rates are significantly elevated, generating a matrix of p-values.",
            "status": "pending",
            "testStrategy": "Confirm that tests are run for all miRNA-position pairs and that p-values are within expected ranges."
          },
          {
            "id": 3,
            "title": "Apply BH-FDR Correction to Test Results",
            "description": "Adjust the matrix of p-values for multiple comparisons using the Benjamini-Hochberg False Discovery Rate (BH-FDR) procedure.",
            "dependencies": [
              "16.2"
            ],
            "details": "Implement BH-FDR correction across all miRNA×position tests, outputting adjusted p-values for downstream visualization and reporting.",
            "status": "pending",
            "testStrategy": "Check that FDR-adjusted p-values are correctly computed and that the number of significant results matches expectations under FDR control."
          },
          {
            "id": 4,
            "title": "Output Statistical Test Results Table",
            "description": "Export the final table of per-miRNA, per-position test statistics and adjusted p-values to a standardized TSV file.",
            "dependencies": [
              "16.3"
            ],
            "details": "Format and write the results to tables/miRNA_position_tests.tsv, ensuring all relevant columns (miRNA, position, raw p-value, adjusted p-value, effect size) are included.",
            "status": "pending",
            "testStrategy": "Validate output file structure, column completeness, and data integrity."
          },
          {
            "id": 5,
            "title": "Generate and Save Per-miRNA Positionwise Heatmaps",
            "description": "Visualize the adjusted p-values or mutation rates as heatmaps for each miRNA using the pheatmap R package, and save the resulting figures.",
            "dependencies": [
              "16.4"
            ],
            "details": "Create heatmaps (e.g., fig/seed_heatmap_by_miRNA.png) displaying mutation rates or significance across miRNA positions, ensuring clear labeling and color scaling.",
            "status": "pending",
            "testStrategy": "Inspect heatmaps for accuracy, clarity, and correspondence with underlying data; confirm output file is generated as specified."
          }
        ]
      },
      {
        "id": 17,
        "title": "Batch/Timepoint Stratified Consistency Checks",
        "description": "Test for consistency of signals across batches, timepoints, and sites.",
        "details": "In R/stats.R, fit interaction terms or stratified GLMMs. Output tables/batch_stratified_tests.tsv, fig/batch_facet_plots.png.",
        "testStrategy": "Check for batch effects and plot stratified results.",
        "priority": "medium",
        "dependencies": [
          16
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Stratification Variables and Prepare Metadata",
            "description": "Identify and extract relevant batch, timepoint, and site variables from sample metadata to enable stratified analysis.",
            "dependencies": [],
            "details": "Parse sample metadata to ensure all samples are annotated with batch, timepoint, and site information. Validate completeness and consistency of these annotations.",
            "status": "pending",
            "testStrategy": "Check that all samples have non-missing batch, timepoint, and site fields. Confirm metadata table matches expected schema."
          },
          {
            "id": 2,
            "title": "Fit Stratified GLMMs and Interaction Models",
            "description": "Fit generalized linear mixed models (GLMMs) with interaction terms or stratified by batch, timepoint, and site to test for consistency of signals.",
            "dependencies": [
              "17.1"
            ],
            "details": "In R/stats.R, use lme4 or similar packages to fit models including fixed effects for group and random effects for batch, timepoint, and site. Include interaction terms as appropriate to assess consistency.",
            "status": "pending",
            "testStrategy": "Verify model convergence and inspect model summaries for inclusion of all relevant terms. Confirm that models run without errors for all strata."
          },
          {
            "id": 3,
            "title": "Generate and Summarize Statistical Test Results",
            "description": "Extract and summarize statistical test results from fitted models, including p-values and effect sizes for batch, timepoint, and site effects.",
            "dependencies": [
              "17.2"
            ],
            "details": "Output results to tables/batch_stratified_tests.tsv, including estimates, confidence intervals, and significance for each stratum and interaction.",
            "status": "pending",
            "testStrategy": "Cross-check output table for completeness and accuracy. Validate that all expected strata and terms are present."
          },
          {
            "id": 4,
            "title": "Visualize Stratified Results",
            "description": "Create visualizations (e.g., faceted plots) to illustrate consistency or heterogeneity of signals across batches, timepoints, and sites.",
            "dependencies": [
              "17.3"
            ],
            "details": "In R/stats.R, generate and save plots (e.g., fig/batch_facet_plots.png) showing stratified results, such as effect sizes or residuals by batch/timepoint/site.",
            "status": "pending",
            "testStrategy": "Confirm that plots are generated for all relevant strata and saved to the correct location. Visually inspect plots for clarity and correctness."
          },
          {
            "id": 5,
            "title": "Interpret and Document Consistency Checks",
            "description": "Interpret statistical and visual results to assess consistency of signals, and document findings and any detected batch/timepoint/site effects.",
            "dependencies": [
              "17.4"
            ],
            "details": "Summarize key findings in project documentation, noting any significant inconsistencies or batch effects and their potential impact on downstream analyses.",
            "status": "pending",
            "testStrategy": "Review documentation for completeness and clarity. Ensure all major findings and caveats are described."
          }
        ]
      },
      {
        "id": 18,
        "title": "Build Per-miRNA Seed Vectors",
        "description": "Construct seed vectors [VAF at pos 2..8] for each miRNA.",
        "details": "In R/cluster.R, aggregate VAFs for positions 2–8 per miRNA. Output tables/seed_vectors.tsv.",
        "testStrategy": "Validate vector construction and output format.",
        "priority": "medium",
        "dependencies": [
          7,
          6
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Extract VAF Data for miRNA Positions 2–8",
            "description": "Retrieve and organize variant allele frequency (VAF) data for each miRNA at nucleotide positions 2 through 8 from the relevant input datasets.",
            "dependencies": [],
            "details": "Access the processed mutation or variant data and filter for the required miRNA entries and positions. Ensure data integrity and completeness for all miRNAs.",
            "status": "pending",
            "testStrategy": "Verify that all miRNAs have VAF data for positions 2–8 and that no positions are missing or duplicated."
          },
          {
            "id": 2,
            "title": "Aggregate VAFs Per miRNA Seed Region",
            "description": "Aggregate the extracted VAFs for positions 2–8 to construct a seed vector for each miRNA.",
            "dependencies": [
              "18.1"
            ],
            "details": "For each miRNA, create a vector of VAFs corresponding to positions 2–8, maintaining the correct order and association.",
            "status": "pending",
            "testStrategy": "Check that each miRNA has a vector of exactly 7 values (one per position) and that aggregation matches the raw data."
          },
          {
            "id": 3,
            "title": "Format Seed Vectors for Output",
            "description": "Format the aggregated seed vectors into a structured table suitable for downstream analysis and export.",
            "dependencies": [
              "18.2"
            ],
            "details": "Create a data frame or table with miRNA identifiers as rows and VAFs at positions 2–8 as columns, ensuring consistent naming and ordering.",
            "status": "pending",
            "testStrategy": "Validate that the output table structure matches the required schema and is compatible with downstream tools."
          },
          {
            "id": 4,
            "title": "Export Seed Vectors to TSV File",
            "description": "Write the formatted seed vector table to 'tables/seed_vectors.tsv' in tab-separated format.",
            "dependencies": [
              "18.3"
            ],
            "details": "Ensure the output file is correctly written, with appropriate headers and no extraneous formatting or missing values.",
            "status": "pending",
            "testStrategy": "Confirm the file exists, is readable, and matches the expected format and content."
          },
          {
            "id": 5,
            "title": "Validate Seed Vector Construction and Output",
            "description": "Perform quality control checks to ensure the correctness of seed vector construction and output file integrity.",
            "dependencies": [
              "18.4"
            ],
            "details": "Cross-check a sample of seed vectors against the original data, and verify that the output file meets all project requirements.",
            "status": "pending",
            "testStrategy": "Spot-check several miRNAs for accuracy, confirm file format, and ensure reproducibility of the process."
          }
        ]
      },
      {
        "id": 19,
        "title": "De Novo Seed-Cluster Discovery and Model Selection",
        "description": "Cluster seed vectors using Ward, HDBSCAN, and Spectral methods; select model by silhouette, DB, and bootstrap ARI.",
        "details": "In R/cluster.R, use cluster (>=2.1.4), dbscan (>=1.1-11), kernlab (>=0.9-32). Bootstrap ARI with fpc (>=2.2-10). Output tables/cluster_membership.tsv, cluster_stability.tsv, fig/cluster_consensus_map.png.",
        "testStrategy": "Check cluster assignments, stability metrics, and consensus map.",
        "priority": "high",
        "dependencies": [
          18
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Clustering with Ward, HDBSCAN, and Spectral Methods",
            "description": "Apply Ward hierarchical clustering, HDBSCAN, and Spectral clustering algorithms to the seed vectors using the specified R packages.",
            "dependencies": [],
            "details": "Use cluster (>=2.1.4) for Ward, dbscan (>=1.1-11) for HDBSCAN, and kernlab (>=0.9-32) for Spectral clustering in R/cluster.R. Ensure input data is correctly formatted for each method.",
            "status": "pending",
            "testStrategy": "Verify that each algorithm produces cluster assignments for all seed vectors and that outputs are reproducible."
          },
          {
            "id": 2,
            "title": "Evaluate Clustering Results with Silhouette and Davies-Bouldin Indices",
            "description": "Compute silhouette scores and Davies-Bouldin (DB) indices for each clustering result to assess cluster quality.",
            "dependencies": [
              "19.1"
            ],
            "details": "Use appropriate functions from the cluster package to calculate silhouette and DB indices for each clustering solution.",
            "status": "pending",
            "testStrategy": "Check that scores are computed for all clustering outputs and that values are within expected ranges."
          },
          {
            "id": 3,
            "title": "Assess Cluster Stability via Bootstrap ARI",
            "description": "Perform bootstrap resampling and compute Adjusted Rand Index (ARI) to evaluate the stability of each clustering method.",
            "dependencies": [
              "19.1"
            ],
            "details": "Use the fpc (>=2.2-10) package to bootstrap cluster assignments and calculate ARI for each method, summarizing stability across resamples.",
            "status": "pending",
            "testStrategy": "Confirm that ARI values are generated for all methods and that bootstrap replicates are sufficient for robust estimates."
          },
          {
            "id": 4,
            "title": "Select Optimal Clustering Model Based on Evaluation Metrics",
            "description": "Compare clustering methods using silhouette, DB, and bootstrap ARI metrics to select the best-performing model.",
            "dependencies": [
              "19.2",
              "19.3"
            ],
            "details": "Integrate all evaluation metrics to rank clustering methods and document the rationale for model selection.",
            "status": "pending",
            "testStrategy": "Ensure the selected model is justified by the metrics and that the selection process is reproducible."
          },
          {
            "id": 5,
            "title": "Generate Output Tables and Consensus Map Visualization",
            "description": "Produce cluster membership and stability tables, and create a consensus map figure summarizing clustering results.",
            "dependencies": [
              "19.4"
            ],
            "details": "Write tables/cluster_membership.tsv, tables/cluster_stability.tsv, and generate fig/cluster_consensus_map.png in R/cluster.R.",
            "status": "pending",
            "testStrategy": "Validate that all output files are correctly formatted, complete, and visually represent the clustering consensus."
          }
        ]
      },
      {
        "id": 20,
        "title": "ALS-Bias Testing in Discovered Clusters",
        "description": "Test if discovered clusters are ALS-biased using χ²/Fisher/GLM.",
        "details": "In R/cluster.R, compare cluster prevalence in ALS vs Control. Output tables/cluster_bias_tests.tsv.",
        "testStrategy": "Validate statistical tests and output.",
        "priority": "medium",
        "dependencies": [
          19
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Prepare Cluster Membership and Phenotype Data",
            "description": "Aggregate cluster assignments and ALS/control phenotype labels for all samples from previous clustering results.",
            "dependencies": [],
            "details": "Extract cluster membership and phenotype (ALS or Control) for each sample from the output of the prior clustering step (e.g., tables/cluster_membership.tsv). Ensure data integrity and correct mapping between cluster assignments and phenotypes.",
            "status": "pending",
            "testStrategy": "Verify that all samples have both cluster and phenotype labels, and that counts match expected totals from previous steps."
          },
          {
            "id": 2,
            "title": "Tabulate Cluster Prevalence by Phenotype",
            "description": "Compute contingency tables showing the prevalence of each cluster in ALS versus Control groups.",
            "dependencies": [
              "20.1"
            ],
            "details": "For each discovered cluster, count the number of ALS and Control samples assigned. Generate a contingency table for each cluster summarizing these counts.",
            "status": "pending",
            "testStrategy": "Check that the sum of counts per cluster matches the total number of samples and that tables are formatted correctly for downstream statistical testing."
          },
          {
            "id": 3,
            "title": "Perform Statistical Bias Tests for Each Cluster",
            "description": "Apply χ² test, Fisher's exact test, or GLM as appropriate to assess whether cluster prevalence is significantly different between ALS and Control groups.",
            "dependencies": [
              "20.2"
            ],
            "details": "For each cluster, select the appropriate statistical test based on sample size and expected counts. Run χ² test for large counts, Fisher's exact test for small counts, and optionally fit a GLM to model cluster assignment as a function of phenotype.",
            "status": "pending",
            "testStrategy": "Validate that statistical tests are correctly chosen and executed for each cluster, and that p-values and effect sizes are computed."
          },
          {
            "id": 4,
            "title": "Aggregate and Format Statistical Test Results",
            "description": "Collect test statistics, p-values, and effect size estimates for all clusters into a single summary table.",
            "dependencies": [
              "20.3"
            ],
            "details": "For each cluster, record the test used, test statistic, p-value, and any relevant effect size (e.g., odds ratio from Fisher/GLM). Format results as a tab-separated table suitable for downstream analysis and reporting.",
            "status": "pending",
            "testStrategy": "Ensure all clusters are represented, columns are complete, and values are consistent with raw test outputs."
          },
          {
            "id": 5,
            "title": "Output Results to cluster_bias_tests.tsv",
            "description": "Write the aggregated statistical test results to tables/cluster_bias_tests.tsv for use in reporting and downstream tasks.",
            "dependencies": [
              "20.4"
            ],
            "details": "Export the formatted summary table to the specified output file path, ensuring correct file structure and accessibility.",
            "status": "pending",
            "testStrategy": "Confirm that the output file exists, is readable, and contains all expected results in the correct format."
          }
        ]
      },
      {
        "id": 21,
        "title": "Build Oxidation-Mimic Seeds",
        "description": "For each miRNA and affected position set, generate mimic seeds (G→U at affected positions).",
        "details": "In R/targets.R, implement mimic seed generator. Output tables/mimic_seeds.tsv.",
        "testStrategy": "Check mimic seed correctness for test cases.",
        "priority": "medium",
        "dependencies": [
          20
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Parse miRNA Sequences and Affected Position Sets",
            "description": "Extract all miRNA sequences and their corresponding sets of affected positions from input data sources.",
            "dependencies": [],
            "details": "Implement code in R/targets.R to read and structure miRNA sequences and the list of positions where G→U mutations should be applied.",
            "status": "pending",
            "testStrategy": "Verify that all miRNAs and affected positions are correctly parsed for a set of test cases."
          },
          {
            "id": 2,
            "title": "Identify G Nucleotides at Affected Positions",
            "description": "For each miRNA, determine which affected positions contain a G nucleotide that can be mutated.",
            "dependencies": [
              "21.1"
            ],
            "details": "Check each affected position in the miRNA sequence to confirm the presence of G; skip or flag positions where G is absent.",
            "status": "pending",
            "testStrategy": "Ensure that only positions with G are selected for mimic seed generation in test cases."
          },
          {
            "id": 3,
            "title": "Generate Mimic Seed Sequences (G→U Substitution)",
            "description": "Create new miRNA seed sequences by substituting G with U at each affected position for every miRNA.",
            "dependencies": [
              "21.2"
            ],
            "details": "Implement logic to generate all possible mimic seeds for each miRNA and affected position set, applying G→U substitutions as specified.",
            "status": "pending",
            "testStrategy": "Confirm that mimic seeds are generated correctly for known input-output pairs."
          },
          {
            "id": 4,
            "title": "Format and Aggregate Mimic Seed Output Table",
            "description": "Compile all generated mimic seeds into a structured table with relevant metadata (miRNA ID, original sequence, affected positions, mimic seed sequence).",
            "dependencies": [
              "21.3"
            ],
            "details": "Ensure the output table matches the required schema for tables/mimic_seeds.tsv.",
            "status": "pending",
            "testStrategy": "Validate table formatting and completeness for a sample dataset."
          },
          {
            "id": 5,
            "title": "Write Mimic Seed Table to Output File",
            "description": "Export the aggregated mimic seed table to tables/mimic_seeds.tsv in the specified format.",
            "dependencies": [
              "21.4"
            ],
            "details": "Implement file writing logic in R/targets.R to output the final table.",
            "status": "pending",
            "testStrategy": "Check that the output file is correctly written and matches expected content for test cases."
          }
        ]
      },
      {
        "id": 22,
        "title": "Predict Canonical vs Mimic Targets and Compute ΔTargets",
        "description": "Run ≥2 predictors for canonical and mimic seeds, compute Δtargets, and visualize overlaps.",
        "details": "In R/targets.R, use at least two target prediction tools (e.g., TargetScan 8.0, miRanda 3.3a). Output tables/targets_*, targets_delta_*, fig/upset_delta_targets.png.",
        "testStrategy": "Compare predictor outputs, check Δtargets, and visualize overlaps.",
        "priority": "high",
        "dependencies": [
          21
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Prepare Canonical and Mimic Seed Input Data",
            "description": "Format and organize canonical and mimic seed sequences for input into target prediction tools, ensuring compatibility with each tool’s requirements.",
            "dependencies": [],
            "details": "Collect and preprocess canonical and mimic seed sequences, ensuring they are in the correct FASTA or tabular format for tools like TargetScan 8.0 and miRanda 3.3a.",
            "status": "pending",
            "testStrategy": "Verify that all input files are correctly formatted and contain the expected sequences for both canonical and mimic seeds."
          },
          {
            "id": 2,
            "title": "Run Multiple Target Prediction Tools",
            "description": "Execute at least two target prediction tools (e.g., TargetScan 8.0, miRanda 3.3a) for both canonical and mimic seed sets to generate predicted target lists.",
            "dependencies": [
              "22.1"
            ],
            "details": "Run each tool separately for canonical and mimic seeds, saving output tables as targets_* for each tool and seed type.",
            "status": "pending",
            "testStrategy": "Confirm successful completion of each tool’s run and validate that output tables contain predicted targets for both seed types."
          },
          {
            "id": 3,
            "title": "Aggregate and Compare Predicted Targets",
            "description": "Combine and compare predicted target lists from all tools for canonical and mimic seeds, identifying overlaps and differences.",
            "dependencies": [
              "22.2"
            ],
            "details": "Merge output tables, compute intersections and unions, and prepare summary tables showing overlaps and unique targets for each seed and tool.",
            "status": "pending",
            "testStrategy": "Check that aggregation correctly reflects overlaps and differences; validate with sample data and manual spot checks."
          },
          {
            "id": 4,
            "title": "Compute ΔTargets Between Canonical and Mimic Predictions",
            "description": "Calculate the difference (Δtargets) between canonical and mimic predicted target sets for each tool and in aggregate.",
            "dependencies": [
              "22.3"
            ],
            "details": "Generate targets_delta_* tables quantifying targets gained, lost, or unchanged between canonical and mimic predictions.",
            "status": "pending",
            "testStrategy": "Verify that Δtargets tables accurately reflect differences; cross-check with manual calculations for selected examples."
          },
          {
            "id": 5,
            "title": "Visualize Overlaps and ΔTargets",
            "description": "Create visualizations (e.g., upset plots) to illustrate overlaps and differences in predicted targets between canonical and mimic seeds across tools.",
            "dependencies": [
              "22.4"
            ],
            "details": "Generate fig/upset_delta_targets.png and related plots to display overlaps and Δtargets, using R visualization libraries.",
            "status": "pending",
            "testStrategy": "Confirm that plots are generated, readable, and accurately represent the computed overlaps and differences."
          }
        ]
      },
      {
        "id": 23,
        "title": "Pathway Enrichment and ALS-Relevance Tagging",
        "description": "Run GO/KEGG enrichment on Δtargets, apply BH-FDR, and tag ALS-relevant themes.",
        "details": "In R/targets.R, use clusterProfiler (>=4.8.1) for enrichment. Output tables/enrichment_*, fig/enrichment_heatmap.png, tables/als_theme_overlap.tsv.",
        "testStrategy": "Validate enrichment results and ALS theme tagging.",
        "priority": "medium",
        "dependencies": [
          22
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Prepare Δtargets Gene List and Annotation Mapping",
            "description": "Extract the Δtargets gene list and ensure gene identifiers are compatible with clusterProfiler's requirements for GO and KEGG enrichment (e.g., convert to ENTREZID if necessary).",
            "dependencies": [],
            "details": "Use R/targets.R to load Δtargets and perform any required ID conversion using clusterProfiler utilities such as bitr().",
            "status": "pending",
            "testStrategy": "Verify that the gene list is correctly formatted and all IDs are successfully mapped for downstream enrichment."
          },
          {
            "id": 2,
            "title": "Run GO and KEGG Pathway Enrichment Analysis",
            "description": "Perform GO and KEGG enrichment analysis on the Δtargets gene list using clusterProfiler (>=4.8.1).",
            "dependencies": [
              "23.1"
            ],
            "details": "Apply enrichGO() and enrichKEGG() functions with appropriate parameters. Save raw enrichment results to tables/enrichment_*.",
            "status": "pending",
            "testStrategy": "Check that enrichment result tables are generated and contain expected pathway and statistical columns."
          },
          {
            "id": 3,
            "title": "Apply Benjamini-Hochberg FDR Correction",
            "description": "Adjust p-values from enrichment results using the Benjamini-Hochberg FDR method and filter for significant pathways.",
            "dependencies": [
              "23.2"
            ],
            "details": "Use p.adjust() or built-in clusterProfiler FDR correction. Filter results by adjusted p-value threshold (e.g., q < 0.05).",
            "status": "pending",
            "testStrategy": "Confirm that adjusted p-values are present and significant pathways are correctly filtered in output tables."
          },
          {
            "id": 4,
            "title": "Tag ALS-Relevant Themes in Enriched Pathways",
            "description": "Annotate or tag enriched pathways with ALS-relevant themes based on curated lists or keyword matching.",
            "dependencies": [
              "23.3"
            ],
            "details": "Cross-reference significant pathways with ALS-related gene sets or literature-derived themes. Output tables/als_theme_overlap.tsv.",
            "status": "pending",
            "testStrategy": "Validate that ALS-relevant tags are correctly assigned and overlap table is generated."
          },
          {
            "id": 5,
            "title": "Generate Enrichment Heatmap Visualization",
            "description": "Create a heatmap summarizing the enrichment results and ALS theme overlaps for visual interpretation.",
            "dependencies": [
              "23.4"
            ],
            "details": "Use R visualization libraries (e.g., ggplot2, pheatmap) to plot enrichment significance and ALS theme tagging. Save as fig/enrichment_heatmap.png.",
            "status": "pending",
            "testStrategy": "Check that the heatmap is generated, visually clear, and accurately reflects the enrichment and tagging results."
          }
        ]
      },
      {
        "id": 24,
        "title": "Stability and Convergence of ΔTargets/Terms",
        "description": "Bootstrap resample Δtargets/terms, compute predictor Jaccard overlaps, and assess stability.",
        "details": "In R/targets.R, implement bootstrap resampling and Jaccard calculation. Output tables/enrichment_stability.tsv, fig/enrichment_overlap.png.",
        "testStrategy": "Check stability indices and convergence metrics.",
        "priority": "medium",
        "dependencies": [
          23
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Bootstrap Resampling of ΔTargets/Terms",
            "description": "Develop R code to perform bootstrap resampling on Δtargets/terms to generate multiple resampled datasets for stability assessment.",
            "dependencies": [],
            "details": "In R/targets.R, write functions to repeatedly sample Δtargets/terms with replacement, storing each resampled set for downstream analysis.",
            "status": "pending",
            "testStrategy": "Verify that the resampling procedure produces the expected number of bootstrap samples and preserves the distributional properties of the original data."
          },
          {
            "id": 2,
            "title": "Calculate Pairwise Jaccard Overlaps for Predictors",
            "description": "For each bootstrap resample, compute pairwise Jaccard coefficients between predictors to quantify overlap in Δtargets/terms.",
            "dependencies": [
              "24.1"
            ],
            "details": "Implement Jaccard coefficient calculation in R, ensuring binary input and correct handling of missing values. Store results in a matrix for each resample.",
            "status": "pending",
            "testStrategy": "Check that Jaccard matrices are symmetric, values are between 0 and 1, and results match manual calculations for test cases."
          },
          {
            "id": 3,
            "title": "Aggregate Jaccard Overlap Results Across Bootstraps",
            "description": "Summarize the distribution of Jaccard overlaps across all bootstrap samples to assess variability and stability.",
            "dependencies": [
              "24.2"
            ],
            "details": "Compute summary statistics (mean, median, variance) for each predictor pair's Jaccard overlaps across bootstraps. Prepare data for output and visualization.",
            "status": "pending",
            "testStrategy": "Confirm that summary statistics are correctly computed and reflect the underlying bootstrap distributions."
          },
          {
            "id": 4,
            "title": "Output Stability Assessment Table",
            "description": "Write a table (tables/enrichment_stability.tsv) summarizing stability metrics for Jaccard overlaps and convergence indices.",
            "dependencies": [
              "24.3"
            ],
            "details": "Format and export a TSV file containing stability indices (e.g., mean, standard deviation, confidence intervals) for each predictor pair.",
            "status": "pending",
            "testStrategy": "Validate table structure, check for completeness, and ensure values match aggregated results."
          },
          {
            "id": 5,
            "title": "Visualize Enrichment Overlap and Stability",
            "description": "Generate a figure (fig/enrichment_overlap.png) visualizing Jaccard overlaps and their stability across bootstraps.",
            "dependencies": [
              "24.3"
            ],
            "details": "Create a heatmap or similar plot in R to display pairwise Jaccard overlaps, highlighting stability and convergence patterns.",
            "status": "pending",
            "testStrategy": "Inspect the figure for clarity, accuracy, and correct mapping of summary statistics to visual elements."
          }
        ]
      },
      {
        "id": 25,
        "title": "Adaptive Controller and Run Registry Implementation",
        "description": "Implement adaptive controller logic (Gate A/B), threshold grid search, and run registry writer.",
        "details": "In controller.R, implement logic to read diagnostics, propose next questions, and write runs/<timestamp>/run.json. Use yaml (>=2.3.7) for config, jsonlite (>=1.8.7) for run.json. Automate threshold sweep and branch decisions.",
        "testStrategy": "Simulate Q→A loop, verify registry logs, and confirm adaptive branching.",
        "priority": "high",
        "dependencies": [
          24
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Adaptive Controller Logic (Gate A/B)",
            "description": "Develop the core adaptive controller logic in controller.R to read diagnostics, determine current state, and select Gate A or Gate B for branching decisions.",
            "dependencies": [],
            "details": "Design functions to process diagnostic inputs and dynamically select the next gate (A or B) based on adaptive criteria. Ensure the logic supports real-time updates and branching.",
            "status": "pending",
            "testStrategy": "Simulate diagnostic input scenarios and verify that the controller selects the correct gate and adapts as expected."
          },
          {
            "id": 2,
            "title": "Automate Threshold Grid Search",
            "description": "Implement automated threshold sweeping logic to systematically explore and evaluate different threshold values for adaptive branching.",
            "dependencies": [
              "25.1"
            ],
            "details": "Create a grid search routine in controller.R that iterates over a range of threshold values, records outcomes, and integrates with the adaptive controller logic.",
            "status": "pending",
            "testStrategy": "Run the grid search on test data and confirm that all threshold values are evaluated and results are logged."
          },
          {
            "id": 3,
            "title": "Propose Next Questions Based on Diagnostics",
            "description": "Develop logic to propose the next set of questions or actions based on current diagnostics and controller state.",
            "dependencies": [
              "25.1",
              "25.2"
            ],
            "details": "Implement a decision module that, after each diagnostic read and threshold evaluation, determines and outputs the next questions to be asked in the adaptive process.",
            "status": "pending",
            "testStrategy": "Simulate Q→A loops and verify that the proposed questions are contextually appropriate and adapt to changing diagnostics."
          },
          {
            "id": 4,
            "title": "Write Run Registry (run.json) with Metadata",
            "description": "Implement functionality to write detailed run metadata to runs/<timestamp>/run.json using jsonlite, capturing all relevant parameters, decisions, and outcomes.",
            "dependencies": [
              "25.1",
              "25.2",
              "25.3"
            ],
            "details": "Ensure that each run is logged with a unique timestamp, includes all adaptive decisions, thresholds, and diagnostic summaries, and is formatted according to project schema.",
            "status": "pending",
            "testStrategy": "Execute multiple runs and verify that run.json files are correctly created, complete, and schema-compliant."
          },
          {
            "id": 5,
            "title": "Integrate YAML Configuration Parsing",
            "description": "Add support for reading and applying configuration parameters from YAML files using the yaml package.",
            "dependencies": [
              "25.1"
            ],
            "details": "Implement config parsing at the start of controller.R, ensuring all adaptive logic and grid search routines use parameters from the YAML config.",
            "status": "pending",
            "testStrategy": "Test with various YAML configs and confirm that all parameters are correctly loaded and reflected in controller behavior."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-09-19T15:23:19.058Z",
      "updated": "2025-09-21T23:01:11.233Z",
      "description": "Tasks for master context"
    }
  }
}