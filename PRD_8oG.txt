<PRD>
# Title
Adaptive ALS miRNA Oxidation — Live, Question-Driven Notebook with De Novo Seed-Cluster Discovery and Functional Inference
(Taskmaster orchestration + Cursor implementation; reusable with evolving data)

# Vision
We will build a **live, adaptable research notebook** that:
1) Learns from every run (Q→A loops), updates thresholds/models, and **records decisions**.
2) Focuses on **oxidative damage signals** in miRNAs using **G>T** as an o8G-like proxy, with emphasis on **seed positions 2–8**, yet open to ALS-specific patterns beyond the seed.
3) Moves from **counts → positional signals → de novo clusters → functional inference** (canonical vs oxidation-mimic seeds → Δtargets → pathway enrichment).
4) Preserves **order and memory**: strict module APIs, deterministic outputs, and a **run registry** for provenance and diffs.
5) **Reuses** solid parts of the current notebook and wraps them as modules (no code thrown away; only upgraded).

# Data Contract (matches your table)
Columns:
- `miRNA name` — canonical miRNA ID (e.g., hsa-miR-xxx-3p).
- `pos:mut` — “position:mutation” within the miRNA (e.g., `5:G>T`).
- **Per-sample SNV columns (one per sample, no suffix)** — read counts supporting that SNV in that sample.
- **Per-sample TOTAL columns (paired, suffix ` (PM+1MM+2MM)` )** — total miRNA reads in that sample (perfect match + up to 2 mismatches).
- With these, compute **VAF** per cell: `VAF = SNV_count / Total_miRNA` (enforced invariant: SNV ≤ Total).
Cohorts / sample naming (examples you provided):  
- `ALS_enrolment`, `ALS_longitudinal_2 / _3 / _4`, `CONTROL` (e.g., `Magen-control-control-...`).

# Reproducibility & Memory
- **Directories**: `fig/`, `tables/`, `runs/`, `R/` (modules), `report.Rmd`, `config.yaml`, `data_schema.json`.
- **Run Registry**: `runs/<timestamp>/run.json` logs: dataset hash, parameters, thresholds chosen, branch decisions, diagnostics, and artifact manifest.
- **Deterministic paths**: Every figure/table has a stable filename (see Outputs).

# Module Layout (reusing your code where possible)
- `R/io.R` — read matrix; pair SNV columns with TOTAL columns via base sample name; parse cohorts/timepoints from names.
- `R/qc.R` — schema checks; invariants (SNV ≤ Total); NA/missingness; coverage summaries.
- `R/normalize.R` — library size `R_p` from totals; compute SNV-RPM; compute VAF (primary endpoint).
- `R/seedmap.R` — parse `pos:mut` → integer `pos` & `mut` (e.g., `G>T`); `mark_seed(pos, window=[2,8])`.
- `R/stats.R` — GLMM/permutation tests; BH-FDR; effect sizes; seed vs non-seed enrichment; stratification by batch/timepoint.
- `R/cluster.R` — build per-miRNA seed vectors (positions 2–8), run Ward/HDBSCAN/Spectral; model selection by silhouette/DB + bootstrap ARI; ALS-bias tests.
- `R/targets.R` — oxidation-mimic seeds (G→U at affected positions), predictors (pluggable), Δtargets, GO/KEGG enrichment, stability across predictors.
- `R/plots.R` — all visualizations (including your “seed shaded + stars” barplot).
- `controller.R` — Adaptive Controller (decision gates, threshold sweeps, window adjustments, next-run suggestions).

# Inputs & Invariants
- **Invariants**: for each sample, miRNA, position, mutation → `SNV_count ≤ Total_miRNA`; totals ≥ 0.
- **Normalization**: compute per-sample library size `R_p` = Σ(Total_miRNA); produce **SNV-RPM** and **VAF** (primary).
- **Metadata inference**: regex rules map sample names to `{group, timepoint, subject_id?, batch?}` with a mapping table saved to `tables/sample_metadata.tsv`.

# Outputs (stable filenames)
fig/
  global_position_barplot.{png,svg}
  composition_G_changes.{png,svg}
  seed_heatmap_top_miRNAs.{png,svg}
  cluster_consensus_map.{png,svg}
  position_delta_curve.{png,svg}
  volcano_position_effects.{png,svg}
  longitudinal_position_trajectories.{png,svg}
  upset_delta_targets.{png,svg}
  enrichment_heatmap.{png,svg}
tables/
  qc_report.tsv
  libsize.tsv
  snv_rpm_long.tsv
  position_map.tsv
  expr_summary.tsv
  top_miRNAs.tsv
  composition_by_group.tsv
  position_overall_rank.tsv
  seed_position_rank.tsv
  toppos_mutation_mix.tsv
  position_delta.tsv
  position_tests.tsv
  seed_nonseed_enrichment.tsv
  miRNA_position_tests.tsv
  batch_stratified_tests.tsv
  seed_vectors.tsv
  cluster_membership.tsv
  cluster_stability.tsv
  cluster_bias_tests.tsv
  mimic_seeds.tsv
  targets_{miRNA}_{canonical|mimic}.tsv
  targets_delta_{miRNA}.tsv
  enrichment_{miRNA}_{gained|lost}.tsv
  enrichment_stability.tsv
  als_theme_overlap.tsv
  hypothesis_ranking.tsv
  threshold_sweep.tsv
  bootstrap_summary.tsv
runs/
  <timestamp>/run.json

# The Question-Driven Backlog (Q→A loops)
> Each question defines: Method → Artifacts → Decision/Next. The Adaptive Controller reads diagnostics to propose the next questions automatically. Your original objectives are included and expanded.

## A) Data Suitability & Expression
- [ ] **Q1: Which miRNAs are sufficiently expressed to be functionally relevant?**  
  Method: per-miRNA totals per sample; define an expression floor by percentile (default 25th), then **grid-sweep** floors.  
  Artifacts: `expr_summary.tsv`, `top_miRNAs.tsv`, `fig/top_miRNAs_bar.png`.  
  Decision: choose floor maximizing downstream power (record in `run.json`).

- [ ] **Q2: Sample/metadata sanity — cohorts/timepoints parsed correctly?**  
  Method: regex mapping from names → `{group, timepoint}`; manual overrides file supported.  
  Artifacts: `tables/sample_metadata.tsv`.  
  Decision: if mapping uncertain for >2% samples, flag interactive fix.

## B) Global Oxidation Signal (ALS vs Control)
- [ ] **Q3 (Your goal): Are aggregate G>T levels higher in ALS than Controls?**  
  Method: per-sample G>T burdens (counts/RPM/VAF); ALS vs Control via GLM/GLMM; **stratified permutation** by batch/timepoint.  
  Artifacts: `global_gt_tests.tsv`, `fig/gt_violin_by_group.png`.  
  Next: if significant (q<0.05), proceed to positional tests; else trigger **Threshold Sweep** to tune min reads, presence, floors.

- [ ] **Q4 (Your goal): How does G>T compare to other base changes?**  
  Method: composition (G>T, G>A, G>C) by group; multinomial/Dirichlet-multinomial; CIs.  
  Artifacts: `composition_by_group.tsv`, `fig/composition_G_changes.png`.  
  Decision: prioritize G>T downstream if unique driver; else parallel tracks.

## C) Positional Signals (seed vs non-seed; per-position)
- [ ] **Q5 (Your goal): Which positions (1..n) are most mutated overall?**  
  Method: summarize G>T VAF (and RPM) per position; bootstrap CI; rank.  
  Artifacts: `position_overall_rank.tsv`, `fig/position_barplot_overall.png`.

- [ ] **Q6 (Your goal): Within the seed (2..8), which positions are most mutated?**  
  Method: same as Q5 but restricted to seed; shade seed band in plot.  
  Artifacts: `seed_position_rank.tsv`, `fig/seed_position_barplot.png`.

- [ ] **Q7 (Your goal): For top positions, what are the most common mutation types at those positions?**  
  Method: mixture of G>T/G>A/G>C per top position; stacked bars.  
  Artifacts: `toppos_mutation_mix.tsv`, `fig/toppos_mut_mix.png`.

- [ ] **Q8 (Your goal): Which positions are differentially mutated (ALS vs Control)?**  
  Method: per-position GLMM on VAF; BH-FDR across positions; permutation as complement.  
  Artifacts: `position_tests.tsv`, `fig/volcano_position_effects.png`.

- [ ] **Q9 (Your goal): Seed vs non-seed enrichment (both quantity and differential).**  
  Method: binomial/permutation baseline; OR, CI, P, q.  
  Artifacts: `seed_nonseed_enrichment.tsv`, `fig/seed_vs_nonseed_odds.png`.

- [ ] **Q10 (Your goal): Position-specific G>T difference curves (ALS–Control).**  
  Method: ΔVAF (and ΔRPM) per position with CIs; **seed shaded**; add `*` where q<0.05.  
  Artifacts: `position_delta.tsv`, `fig/position_delta_curve.png` (this replicates your favorite figure style).

## D) Per-miRNA Deep Dives (on “top expression” set)
- [ ] **Q11: For each highly expressed miRNA, which seed positions drive ALS signal?**  
  Method: per-miRNA positionwise tests; BH-FDR across miRNA×position.  
  Artifacts: `miRNA_position_tests.tsv`, `fig/seed_heatmap_by_miRNA.png`.

- [ ] **Q12: Consistency across batches/timepoints/sites?**  
  Method: interaction terms or stratified tests; leave-one-batch-out.  
  Artifacts: `batch_stratified_tests.tsv`, `fig/batch_facet_plots.png`.

## E) De Novo Seed-Cluster Discovery (positions 2..8)
- [ ] **Q13: Build per-miRNA seed vectors** `[VAF at pos 2..8]` (len 7).  
  Artifacts: `seed_vectors.tsv`.

- [ ] **Q14: Discover clusters (Ward/HDBSCAN/Spectral) and select a model.**  
  Method: distances = cosine/correlation; select by silhouette + DB + **bootstrap ARI**.  
  Artifacts: `cluster_membership.tsv`, `cluster_stability.tsv`, `fig/cluster_consensus_map.png`.

- [ ] **Q15: Are discovered clusters ALS-biased?**  
  Method: cluster prevalence ALS vs Control; χ²/Fisher/GLM.  
  Artifacts: `cluster_bias_tests.tsv`.  
  **Decision Gate A**: If stable ALS-biased clusters exist → go to Functional layer; else **Threshold Sweep** and re-run C–E. If top signals fall outside seed → mark deviation and schedule non-seed extension.

## F) Functional Layer (post-cluster; many steps)
- [ ] **Q16: Build oxidation-mimic seeds** for each (miRNA, affected position set).  
  Method: G→U at affected positions (o8G•A surrogate).  
  Artifacts: `mimic_seeds.tsv`.

- [ ] **Q17: Canonical vs mimic targets (≥2 predictors).**  
  Method: seed-match scan + alternate heuristic/score; record params; filter by score if needed.  
  Artifacts: `targets_*`, `targets_delta_*`, `fig/upset_delta_targets.png`.  
  Decision: If predictors disagree, run **score-threshold sweep** and re-compute Jaccard overlaps.

- [ ] **Q18: Which pathways/processes are gained/lost? Are they ALS-relevant?**  
  Method: GO/KEGG on Δtargets; BH-FDR; term heatmaps across miRNAs/clusters; tag ALS-relevant themes.  
  Artifacts: `enrichment_*`, `fig/enrichment_heatmap.png`, `als_theme_overlap.tsv`.

- [ ] **Q19: Are Δtargets/terms stable to resampling and convergent across predictors?**  
  Method: bootstrap resample; term overlap; predictor Jaccard.  
  Artifacts: `enrichment_stability.tsv`, `fig/enrichment_overlap.png`.  
  **Decision Gate B**: Converged & stable → **Tier-1** hypotheses; else **Tier-2** exploratory.

- [ ] **Q20: Rank hypotheses for follow-up.**  
  Method: composite score = positional effect + cluster stability + enrichment strength + predictor agreement + expression.  
  Artifacts: `hypothesis_ranking.tsv`, `fig/hypothesis_ranking.png`.

## G) Cross-Checks & Confounders
- [ ] **Q21: Sequence context around oxidized G (±1 nt).**  
  Method: enrichment vs background; logo-like visualization.  
  Artifacts: `sequence_context.tsv`, `fig/sequence_context.png`.

- [ ] **Q22: Mapping/technical biases.**  
  Method: depth/quality covariates; low-complexity checks; include QC covariates in models.  
  Artifacts: `tech_covariate_effects.tsv`, `fig/qc_covariate_plots.png`.

- [ ] **Q23: Family-level signals (e.g., let-7).**  
  Method: aggregate families; compare to per-miRNA results.  
  Artifacts: `family_position_tests.tsv`, `fig/family_seed_heatmap.png`.

## H) Longitudinal (if available)
- [ ] **Q24: Within-subject changes in positional G>T** (progression).  
  Method: paired GLMM; time × group; spaghetti plots by subject.  
  Artifacts: `longitudinal_tests.tsv`, `fig/longitudinal_trajectories.png`.

- [ ] **Q25: Do Δtargets/pathways evolve over time?**  
  Method: canonical vs mimic by timepoint for key miRNAs; track terms.  
  Artifacts: `longitudinal_enrichment.tsv`, `fig/longitudinal_enrichment_heatmap.png`.

## I) Sensitivity & Robustness
- [ ] **Q26: Threshold Sweep** (min_SNV_reads, presence_across_samples, expression_floor_percentile, min_miRNA_total_reads).  
  Method: maximize `S = w1·(−log10 q_seed) + w2·(# ALS-biased clusters) − w3·coverage_penalty`.  
  Artifacts: `threshold_sweep.tsv`, `fig/threshold_response_surface.png`.

- [ ] **Q27: Bootstrap/jackknife stability** (effects, clusters, enrichments).  
  Artifacts: `bootstrap_summary.tsv`, `fig/cluster_stability.png`, `fig/term_stability.png`.

- [ ] **Q28: Stopping rules**  
  Stop a cycle when: (i) q_seed < 0.05, (ii) ≥K miRNAs with stable ALS-biased clusters, (iii) ≥M Tier-1 pathways converged. Otherwise iterate thresholds/predictors.

# Stats (defaults; configurable)
- **Endpoint**: VAF primary; RPM as sensitivity.
- **Models**: GLMM (fixed = group, position; random = subject (if repeated) and/or miRNA).  
- **Permutation**: label shuffles within batch/time strata (1k–10k).  
- **Multiple testing**: BH-FDR for position×miRNA grids and for pathway terms.  
- **Clustering**: Ward (k=1..12), HDBSCAN (min_cluster_size auto), Spectral; distances = cosine/correlation; selection by silhouette + DB + bootstrap ARI.  
- **Convergence**: Predictor Jaccard for Δtargets/terms; stability indices reported.

# Plot Specs (including your favorite figure)
- **Position bars by group** (ALS vs Control) with **seed shaded** (positions 2–8) and `*` for q<0.05 at each position.  
- **Composition bars** for G changes (G>T, G>A, G>C) by group.  
- **Heatmaps** (samples×positions) for top miRNAs.  
- **Consensus cluster map** showing centroid peaks (e.g., {2,3}, {3,4}).  
- **Volcano/forest** of per-position effects.  
- **UpSet/Venn** for Δtargets.  
- **Term heatmaps** for GO/KEGG.  
- **Longitudinal trajectories** per subject (if present).

# Adaptive Controller (gate logic)
Inputs: diagnostics (q_seed, OR_seed, position effect sizes, # ALS-biased clusters, cluster stability, coverage, predictor overlaps).  
Gate A:  
- If q_seed<0.05 and (# ALS-biased clusters ≥ K) and stability≥τ → **run Target Sim**.  
- Else → **Threshold Sweep**, re-evaluate C–E.  
If strongest signals outside seed → record deviation; schedule non-seed extension next run (seed remains primary narrative).  
Gate B:  
- If Δenrichments converge (overlap≥θ) and stable → **Tier-1**; else **Tier-2** and sweep predictor thresholds.

# Reuse of Existing Notebook
- Keep: sample-ID cleaning; wide↔long transforms; RPM/VAF computation; seed parsing; your plotting aesthetics (seed shading, stars).  
- Refactor: mixed chunks to pure functions (no hidden globals); I/O separated from stats/plots.  
- Replace: ad-hoc tests with unified GLMM/permutation + FDR pipeline so decisions are comparable across runs.

# Taskmaster Automations (pasteable)
1) **Nightly Schema/QC** — “Validate schema, SNV≤Total, compute libsize; write `qc_report.tsv`. Fail if <70% samples pass.”  
2) **Weekly Adaptive Run** — “Run notebook with current config. If seed signal weak → Threshold Sweep; else → Target Sim for top clusters. Write `runs/<ts>/run.json` summary.”  
3) **Threshold Sweep (On-Demand)** — “Grid-search floors/presence/min reads/min totals to maximize seed signal and ALS-biased clusters with coverage≥70%.”  
4) **Enrichment Audit** — “Re-run Δtargets with alternate predictor; compute Jaccard; flag <0.4; export audit.”  
5) **Packaging Check** — “Verify lockfile + artifact manifest; fail on missing figs/tables or missing params in run.json.”

# Cursor Work Items (copy/paste prompts)
A) “Create `R/*.R` modules; migrate robust helpers from my existing notebook; add roxygen docs + `stopifnot()`; no side effects except exports.”  
B) “Implement pairing of SNV and TOTAL columns by base sample name (TOTAL has suffix ` (PM+1MM+2MM)`); build `sample_metadata.tsv` from column names.”  
C) “Compute `R_p`, RPM, VAF; produce `snv_rpm_long.tsv` and `position_map.tsv`; add `mark_seed()` for positions 2–8.”  
D) “Implement GLMM + stratified permutation for per-position tests; BH-FDR; seed vs non-seed enrichment; export `position_tests.tsv`.”  
E) “Recreate my favorite figure: grouped bars ALS vs Control, seed region shaded, `*` for q<0.05, y=positional fraction (VAF). Save `position_delta_curve.*` and `global_position_barplot.*`.”  
F) “Build seed vectors 2..8; run Ward/HDBSCAN/Spectral; select model by silhouette + DB + bootstrap ARI; export `cluster_*`.”  
G) “Implement Adaptive Controller (Gate A/B), threshold grid search, and run registry writer.”  
H) “Implement oxidation-mimic seeds, predictors, Δtargets, GO/KEGG enrichment, predictor-overlap metrics; export enrichment outputs and heatmaps.”  
I) “Add longitudinal GLMM (if present) and plots; knit `report.Rmd` with methods/parameters and next-run suggestions.”

# Acceptance Criteria
- End-to-end run with locked env; all artifacts present.  
- Your initial goals are satisfied with explicit tests & figures (Q3–Q10).  
- De novo seed clusters discovered with stability and ALS-bias quantified (Q13–Q15).  
- Functional layer completes with Δtargets and enrichment + stability across predictors (Q16–Q19).  
- Registry shows at least one data-driven branch (Threshold Sweep or Target Sim).  
- Report tells the Q→A story and lists **Next-Run Questions** auto-generated by the controller.

# Next-Run Questions (auto-generator examples)
- If q_seed ≥ 0.05 but non-seed biased → “Extend window to 9–12 next run?”  
- If cluster ARI < τ → “Which threshold combo maximizes ARI with ≥75% coverage?”  
- If predictor overlap < θ → “Raise target score threshold or switch backend?”  
- If Tier-1 terms converge → “Do these terms intensify longitudinally in ALS?”

# Optional Plot Function Spec (for your favorite figure)
`plot_gt_position_by_group(df_long, group_var, seed_window = c(2,8), pvals_table) → ggplot`  
Inputs: long table with `position`, `group`, `metric = VAF`, and a p-adjusted table for stars.  
Output: grouped bars, seed shaded rectangle, stars for q<0.05, saved to `global_position_barplot.*`.

</PRD>
